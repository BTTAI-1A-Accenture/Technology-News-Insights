The cameras at the front of Meta’s Quest VR headsets are off-limits to developers, but developer [Michael Gschwandtner] created a workaround (Linkedin post) and shared implementation details with a VR news site. The demo shows object detection via MobileNet V2, which we’ve seen used for machine vision on embedded systems like the Raspberry Pi. In this case it is running locally on the VR headset, automatically identifying objects even though the app cannot directly access the front-facing cameras to see what’s in front of it. The workaround is conceptually simple, and leverages the headset’s ability to cast its video feed over Wi-Fi to other devices. This feature is normally used for people to share and spectate VR gameplay. First, [Gschwandtner]’s app sets up passthrough video, which means that the camera feed from the front of the headset is used as background in VR, creating a mixed-reality environment. Then the app essentially spawns itself a Chromium browser, and casts its video feed to itself. It is this video that is used to — in a roundabout way — access what the cameras see. The resulting view isn’t really direct from the cameras, it’s akin to snapshotting a through-the-headset view which means it contains virtual elements like the UI. Still, with passthrough turned on it is a pretty clever workaround that is contained entirely on-device. Meta is hesitant to give developers direct access to camera views on their VR headset, and while John Carmack (former Meta consulting CTO) thinks it’s worth opening up and can be done safely, it’s not there yet. With modern tools, you have to try very hard to do something stupid, because the tools (rightly) recognize you’re doing something stupid. [Andreas Karlsson] can speak to that first hand as he tried to get four billion if statements to compile. You may ask what state space requires four billion comparisons to evaluate? The answer is easy: the range of an unsigned 32-bit integer. The whole endeavor started with a simple idea: what if instead of evaluating whether an integer is even or odd with a modulo or bit mask, you just did an if statement for every case? Small ranges like 0-10 are trivial to write out by hand, but you reach for more automated solutions as you pass 8 bits and move towards 16. [Andreas] wrote some Python that outputs a valid C program with all the comparisons. For 16 bits, the source only clocks in at 130k lines with the executable less than 2 MB. Of course, scaling to 32 bits is a very different problem. The source file balloons to 330 GB, and most compilers barf at that point. Undeterred, [Andreas] modified the Python to output x86_64 assembly instead of C. Of course, the executable format of Windows (PE) only allows executables up to 4 GB, so a helper program mapped the 40 GB generated executable and jumped into it. What’s incredible about this whole journey is how performant the program is. Even large numbers complete in a few seconds. Considering that it has to thrash 40 GB of an executable through memory, we can’t help but shake our heads at how even terrible solutions can work. We love seeing someone turn a bad idea into an interesting one, like this desoldering setup. Data manipulation is at the heart of computation, and a system is said to be Turing-complete if it can be configured to manipulate data in a way that makes implementing arbitrary computation possible. [Keigo Oka] shared a proof that find and mkdir together are Turing-complete, which is to say, a system with only GNU’s find and mkdir has access to enough functionality to satisfy the requirements of Turing completeness, which ignores questions of efficiency or speed. [Keigo Oka]’s first attempt at a proof worked to implement Rule 110, an elementary cellular automata configuration that has been shown to be Turing-complete, or ‘universal’, but has been updated to implement a tag system as it’s proof, and you can see it in action for yourself. Seeing basic utilities leveraged in such a way illustrates how computation is all around us, and not always in expected places. We’ve also seen Turing-complete origami and computation in cellular automata. Angry Birds, flash mobs, Russell Brand, fidget spinners. All of these were virtually unavoidable in the previous decade, and yet, like so many popular trends, have now largely faded into obscurity. But in a recent announcement, the developers of LightBurn have brought back a relic of the past that we thought was all but buried along with Harambe — popular software not supporting Linux. But this isn’t a case of the developers not wanting to bring their software to Linux. LightBurn, the defacto tool for controlling hobbyist laser cutters and engravers, was already multi-platform. Looking forward, however, the developers claim that too much of their time is spent supporting and packaging the software for Linux relative to the size of the user base. In an announcement email sent out to users, they reached even deeper into the mid-2000s bag of excuses, and cited the number of Linux distributions as a further challenge: The segmentation of Linux distributions complicates these burdens further — we’ve had to provide three separate packages for the versions of Linux we officially support, and still encounter frequent compatibility issues on those distributions (or closely related distributions), to say nothing of the many distributions we have been asked to support. We’re not sure how much of their time could possibly be taken up by responding to requests for supporting additional distributions (especially when the answer is no), but apparently, it was enough that they finally had to put their foot down — the upcoming 1.7.00 release of LightBurn will be the last to run on Linux.  Continue reading “LightBurn Turns Back The Clock, Bails On Linux Users” → We’ve all been stymied by a smart thermostat, coffee maker, or other device which would work fine on its own but ultimately seems to be worse off for having an Internet connection —  so when something actually pulls off this feat it’s quite noteworthy. [James] has a powerful set of connected speakers and while they don’t have all of the functionality he needed built-in, an included web API at least allowed him to build in the features he wanted. The major problem with these speakers isn’t that they’re incredibly loud (although they are), but rather that the wide range of available volumes for such a loud soundsystem doesn’t leave a lot of fine adjustment in the range where [James] typically uses these speakers. To tackle the problem, he first found the web interface the speakers present and then discovered a somewhat hidden application programming interface (API) within that allows for some manual control. He built a second website which serves as a volume slider within the range he wants, and the web server sends this volume to the speakers via this API which allows much finer control than the built-in user interface. Having a usable API included with Internet-connected devices is not always the case, although it’s a great model for any company wanting to allow their customers better control of the products they buy. If you need to roll out your own API for connected devices that don’t have one already, take a look at [Sean Boyce]’s guide from 2019. The ps command is extremely useful when you want to get some quick information on active system processes (hence the name), especially followed by piping it into grep and kin for some filtering. One gotcha is of course that ps doesn’t run in the current shell process, but is forked off into its own process, so what if everything goes wrong and you absolutely need to run ps aux on a system that is completely and utterly out of fresh process IDs to hand out? In that scenario, you fortunately can write a shell script that does the same, but all within the same shell, as [Isabella Bosia] did, with a Bash shell script. The how and why is mostly covered in the shell script itself, using detailed comments. Initially the hope was to just read out and parse the contents of /proc/<pid>/status, but that doesn’t have details like CPU%. The result is a bit more parsing to get the desired result, as well as a significant amount of cussing in the comments. Even if it’s not entirely practical, as the odds of ending up on a system with zero free PIDs are probably between zero and NaN, but as an ‘entertaining’ job interview question and example of all the fun things one can do with shell scripting it’s definitely highly recommended. For most people, you turn on your computer, and it starts the operating system. However, the reality is much more complex as [Thasso] discovered. Even modern x86 chips start in 16-bit real mode and there is a bit of fancy footwork required to shift to modern protected mode with full 64-bit support. Want to see how? [Thasso] shows us the ropes. Nowadays, it is handy to develop such things because you don’t have to use real hardware. An emulator like QEMU will suffice. If you know assembly language, the process is surprisingly simple, although there is a lot of nuance and subtlety. The biggest task is setting up appropriate paging tables to control the memory mapping. In real mode, segments have access to fixed 64 K blocks of memory unless you use some tricks. But in protected mode, segments define blocks of memory that can be very small or cover the entire address space. These segments define areas of memory even though it is possible to set segments to cover all memory and — sort of — ignore them. You still have to define them for the switch to protected mode. In the bad old days, you had more reason to worry about this if you were writing a DOS Extender or using some tricks to get access to more memory. But still good to know if you are rolling your own operating system. Why do the processors still boot into real mode? Good question. 
						By using our website and services, you expressly agree to the placement of our performance, functionality and advertising cookies. Learn more