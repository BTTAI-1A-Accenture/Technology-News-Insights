On the business, strategy, and impact of technology. Loading Some things in tech are shocking, but not surprising — think of a CEO of a struggling company losing their job. Sure, the news is unexpected, but it makes sense if you think about it. Other news, though, is shocking and surprising, and Google’s February keynote in Paris — which appeared to be a panicked response to Microsoft’s GPT-powered Bing announcement — was both. The shocking part was just how poor the presentation was: there was very little content that was new, the slides and speakers were out of sync, and the nadir came when one of the presenters started a demo and only then realized they didn’t have a phone to demo with. The surprise is that Google would be caught so far out of pocket about AI, and not just because AI would seem to be in Google’s sweet spot: in fact Google has been talking about AI at Google I/O in particular for years now, and I’ve consistently found the company’s framing of its work very impressive. Go back to 2016, when I excerpted CEO Sundar Pichai’s long digression into how machine learning is used in its products and wrote: 
  Note the specificity — it may seem too much for a keynote, but it is absolutely not BS. And no surprise: everything Pichai is talking about is exactly what Google was created to do. It’s no different than Ballmer exclaiming how much he loves Windows: that was the product representation of Microsoft’s mission, a perspective that perhaps grants the deposed CEO just a hint of grace for his inability to move on.   The next 30 minutes were awesome: Google Now, particularly Now on Tap, was exceptionally impressive, and Google Photos looks amazing. And, I might add, it has a killer tagline: Gmail for Photos. It’s so easy to be clear when you’re doing exactly what you were meant to do, and what you are the best in the world at.
 Two years later I called Google I/O boring, and I meant it as a compliment: 
  This is why I think that Pichai’s “boring” opening was a great thing. No, there wasn’t the belligerence of early Google I/Os, insisting that Android could take on the iPhone. And no, there wasn’t the grand vision of Nadella last week, or the excitement of an Apple product unveiling. What there was was a sense of certainty and almost comfort: Google is about organizing the world’s information, and given that Pichai believes the future is about artificial intelligence, specifically the machine learning variant that runs on data, that means that Google will succeed in this new world simply by being itself. That is the best place to be, for a person and for a company.
 That was the year that Google invented the transformer, the key invention undergirding the large language models that power ChatGPT, the product that seemed to fluster Google so much over the past six months. What was impressive about this year’s Google I/O is that it managed to combine what was compelling about Google’s last several I/O’s — its clear AI capabilities and the products in which to manifest them — with the urgency and aggressiveness that are exactly what you would hope to see from a company feeling threatened for the first time in years. I noted above that Google introduced Google Photos as being Gmail for photos; two of my favorites slides from Pichai’s opening remarks showed how both products are evidence of Google’s evolving AI capabilities. Gmail evolved from “Smart Reply” to “Smart Compose” to “Help Me Write”:  Google Photos evolved from “Find Photos” to “Magic Eraser” to “Magic Editor”:  This was a very clever way to reinforce the idea that Google has been at this AI stuff for a while, and it’s true! It was also a reminder that one of Google’s big advantages mirrors Microsoft’s: the company has a bunch of user-facing products in which to surface AI capabilities in genuinely useful ways. Pichai noted that Google had 15 products with over 500 million users:  And six products with 2 billion users:  Perhaps the most notable part of the keynote, though, was Pichai’s opening statement: 
  Seven years into our journey as an AI-first company, we’re at an exciting inflection point. We have an opportunity to make AI even more helpful for people, for businesses, for communities, for everyone. We’ve been applying AI to make our products radically more helpful for a while. With generative AI, we’re taking the next step. With a bold and responsible approach, we are re-imagining all of our core products, including search.
 It seems notable that “responsible” was preceded by “bold”; the overriding message from Google I/O is that Google is in it to win it and, as Pichai noted, that includes search. After Google I/O 2019 — which I also found impressive — I raised the issue of Google’s long-term business model: 
  More importantly, while Google Assistant continues to impress — putting everything on device promises a major breakthrough in speed, a major limiting factor for Assistants today — it is not at all clear what Google’s business model is. It is hard to imagine anything as profitable as search ads, which benefit not only from precise targeting — the user explicitly says what they want! — but also an auction format that leverages the user to pick winners, and incentivizes those winners to overpay for the chance of forming an ongoing relationship with that user.
 Google, as I expected, is taking a hybrid approach: most searches are not commercial, and so Google is going to place generated text right at the top:  For searches that do have commercial possibilities, ads will still get top billing:  This seems like a reasonable approach, aided by the fact that non-commercial searches are probably more likely to benefit from AI anyways; this is also an approach that already looks more compelling and yes, bold, than Microsoft’s grafting on of Bing Chat to the side of traditional search. Of course Microsoft has actually launched its new search experience, and Satya Nadella’s eagerness to chip away at both Google’s marketshare and its margins remains a threat: generating these answers costs money, and Google’s models may still trail GPT-4 on an apples-to-apples basis. Still, this demo specifically and this year’s Google I/O generally are a pretty strong response to what Sam Altman told me in a Stratechery Interview after Bing’s launch: 
  I think it’s fabulous for both of us. I think there’s so much upside for both of us here. We’re going to discover what these new models can do, but if I were sitting on a lethargic search monopoly and had to think about a world where there was going to be a real challenge to the way that monetization of this works and new ad units, and maybe even a temporary downward pressure, I would not feel great about that.
 Those challenges remain, but at least the “lethargic search monopoly” has woken up. If there is one thing everyone is sure about, it is that AI is going to be very disruptive; in January’s AI and the Big Five, though, I noted that it seemed more likely that AI would be a sustaining innovation: 
  The story of 2022 was the emergence of AI, first with image generation models, including DALL-E, MidJourney, and the open source Stable Diffusion, and then ChatGPT, the first text-generation model to break through in a major way. It seems clear to me that this is a new epoch in technology.   To determine how that epoch might develop, though, it is useful to look back 26 years to one of the most famous strategy books of all time: Clayton Christensen’s The Innovator’s Dilemma, particularly this passage on the different kinds of innovations: 
    Most new technologies foster improved product performance. I call these sustaining technologies. Some sustaining technologies can be discontinuous or radical in character, while others are of an incremental nature. What all sustaining technologies have in common is that they improve the performance of established products, along the dimensions of performance that mainstream customers in major markets have historically valued. Most technological advances in a given industry are sustaining in character…     Disruptive technologies bring to a market a very different value proposition than had been available previously. Generally, disruptive technologies underperform established products in mainstream markets. But they have other features that a few fringe (and generally new) customers value. Products based on disruptive technologies are typically cheaper, simpler, smaller, and, frequently, more convenient to use.
     It seems easy to look backwards and determine if an innovation was sustaining or disruptive by looking at how incumbent companies fared after that innovation came to market: if the innovation was sustaining, then incumbent companies became stronger; if it was disruptive then presumably startups captured most of the value.
 My conclusion in that Article was that AI would be a sustaining innovation for Apple, Amazon, Meta, and Microsoft; the big question was Google and search: 
  That Article assumed that Google Assistant was going to be used to differentiate Google phones as an exclusive offering; that ended up being wrong, but the underlying analysis remains valid. Over the past seven years Google’s primary business model innovation has been to cram ever more ads into Search, a particularly effective tactic on mobile. And, to be fair, the sort of searches where Google makes the most money — travel, insurance, etc. — may not be well-suited for chat interfaces anyways.   That, though, ought only increase the concern for Google’s management that generative AI may, in the specific context of search, represent a disruptive innovation instead of a sustaining one. Disruptive innovation is, at least in the beginning, not as good as what already exists; that’s why it is easily dismissed by managers who can avoid thinking about the business model challenges by (correctly!) telling themselves that their current product is better. The problem, of course, is that the disruptive product gets better, even as the incumbent’s product becomes ever more bloated and hard to use — and that certainly sounds a lot like Google Search’s current trajectory.   I’m not calling the top for Google; I did that previously and was hilariously wrong. Being wrong, though, is more often than not a matter of timing: yes, Google has its cloud and YouTube’s dominance only seems to be increasing, but the outline of Search’s peak seems clear even if it throws off cash and profits for years.
 Or maybe not. I tend to believe that disruptive innovations are actually quite rare, but when they come, they are basically impossible for the incumbent company to respond to: their business models, shareholders, and most important customers make it impossible for management to respond. If that is true, though, then an incumbent responding is in fact evidence that an innovation is actually not disruptive, but sustaining. To that end, I take this Google I/O as evidence that AI is in fact a sustaining technology for all of Big Tech, including Google. Moreover, if that is the case, then that is a reason to be less bearish on the search company, because all of the reasons to expect them to have a leadership position — from capabilities to data to infrastructure to a plethora of consumer touch points — remain. Still, the challenges facing search as presently constructed — particularly its ad model — remain. Another question I have been puzzling over is if AI is a Technological Revolution of the sort chronicled by Carlota Perez in Technological Revolutions and Financial Capital. Once again, the conventional wisdom is that AI represent an entirely new paradigm; no less a luminary than Bill Gates wrote: 
  The development of AI is as fundamental as the creation of the microprocessor, the personal computer, the Internet, and the mobile phone. It will change the way people work, learn, travel, get health care, and communicate with each other. Entire industries will reorient around it. Businesses will distinguish themselves by how well they use it…   I’m lucky to have been involved with the PC revolution and the Internet revolution. I’m just as excited about this moment. This new technology can help people everywhere improve their lives. At the same time, the world needs to establish the rules of the road so that any downsides of artificial intelligence are far outweighed by its benefits, and so that everyone can enjoy those benefits no matter where they live or how much money they have. The Age of AI is filled with opportunities and responsibilities.
 Gates insinuates that the PC revolution, the Internet revolution, and the AI revolution are discrete events, but they can also be viewed as three applications of the defining economic feature of digitization — zero marginal costs — to information: Moreover, these three revolutions had to come in the order they did: the very concept of the Internet doesn’t make sense without there being disparate computers, and these AI models are trained on the Internet. I would also note that this progression is in-line with the argument I made in 2020’s The End of the Beginning: my argument in that Article is that the various tech revolutions were all manifestations of the same trend towards continuous computing everywhere; I didn’t mention AI in that Article, but the fact that AI appears to be a sustaining innovation supports the idea that the big winners of tech’s beginning will be the foundation of what happens in tech in the future. Perez for her part has argued that the current revolution is still in the installation phase (I lay out her argument in this Article); for her the missing ingredient is coordination with and by governments. One of Google’s other I/O announcements was the widespread availability of Bard, its ChatGPT competitor. The more interesting news was where it was not available; from Android Authority: 
  Google announced at its I/O developer conference that its Bard chatbot would be broadly available in 180 markets. It marks a major expansion for the platform, which saw a very limited release at first. Canada and Europe are missing from the list of supported markets, though. Now, Google has hinted at a possible reason for these omissions in an emailed response to an Android Authority query. A Google spokesperson noted the following: 
    Bard will soon be able to support the 40 top languages, and while we haven’t finalized the timeline for expansion plans, we will roll it out gradually and responsibly, and continue to be a helpful and engaged partner to regulators as we navigate these new technologies together.
     The company’s assertion that it was a “helpful and engaged partner to regulators” suggests that Bard is skipping the E.U. and Canada for now due to regulatory concerns.
 Once again there is a conventional wisdom take: “Haha silly Europe and its regulations means it will miss out on AI”, and, for now, that’s obviously true. It seems like a safe bet, though, that Google and Microsoft and Meta and other tech giants will indeed be a “helpful and engaged partner to regulators” to their ultimate benefit. After all, consider what those regulations might look like, starting with Canada and this bit from that same article: 
  Canadian lawmakers recently introduced legislation aimed at regulating AI. The Artificial Intelligence and Data Act (AIDA) mandates assessments, risk management, monitoring, data anonymization, transparency, and record-keeping practices around AI systems. AIDA would also introduce penalties of up to 3% of a company’s global revenue or $10 million.
 That is a lot of red tape that will certainly be annoying for Google et al to manage, but also eminently manageable given their scale and resources; a proposed AI law in the E.U. will have an even larger regulatory load. What is notable is that the technological arc I traced above is bending towards more government control: PCs granted incredible freedom and capabilities to individuals, but the Internet’s devolvement into Aggregator-mediated networks gave governments distinct chokepoints on which to push for control of distribution, whether that be explicit as in China or implicit as in much of the West. AI, meanwhile, to the extent it is centralized in the major players, means there are direct loci of control on the actual generation of information. This gives credence to Perez’s argument that the IT revolution has not yet achieved government alignment: it just wasn’t structurally possible previously. Whether said alignment does in fact mean an imminent “Golden Era” as Perez forecasts remains to be seen. What is worth noting is that it is very much in Google’s interest that this alignment becomes concrete: the best way to forestall truly disruptive technologies is to regulate them away. There is another aspect of the E.U. regulations that seems a bit more sinister. From Technomancers.ai: 
  In a bold stroke, the E.U.’s amended AI Act would ban American companies such as OpenAI, Amazon, Google, and IBM from providing API access to generative AI models. The amended act, voted out of committee on Thursday, would sanction American open-source developers and software distributors, such as GitHub, if unlicensed generative models became available in Europe.  While the act includes open source exceptions for traditional machine learning models, it expressly forbids safe-harbor provisions for open source generative systems.   Any model made available in the E.U., without first passing extensive, and expensive, licensing, would subject companies to massive fines of the greater of €20,000,000 or 4% of worldwide revenue. Opensource developers, and hosting services such as GitHub – as importers – would be liable for making unlicensed models available. The E.U. is, essentially, ordering large American tech companies to put American small businesses out of business – and threatening to sanction important parts of the American tech ecosystem.   If enacted, enforcement would be out of the hands of E.U. member states.  Under the AI Act, third parties could sue national governments to compel fines.  The act has extraterritorial jurisdiction.  A European government could be compelled by third parties to seek conflict with American developers and businesses.
 This is a pretty explosive allegation, but Delos Prime, the author, backs it up with citations to the proposed law, and I think it’s a reasonable interpretation. As is ever the case with proposals like this, there isn’t explicit language about, say, banning API access; rather, Prime’s conclusion is that that is the effective outcome of, for example, API providers being made liable for all uses of their API, just as open source authors and distributors would be held liable for all uses of their models. The question of how the U.S. would respond to such a law is obviously a hugely important one: there is a case to be made that making U.S. companies liable for simply open-sourcing models is a flagrant violation of sovereignty; I’m sure the E.U. would argue that U.S. Internet companies effectively exporting U.S. values like free speech was the exact same thing. This is where history is interesting to consider, particularly the invention that I have long held is most analogous to the Internet: the printing press. I wrote in The Internet and the Third Estate: 
  In the Middle Ages the principal organizing entity for Europe was the Catholic Church. Relatedly, the Catholic Church also held a de facto monopoly on the distribution of information: most books were in Latin, copied laboriously by hand by monks. There was some degree of ethnic affinity between various members of the nobility and the commoners on their lands, but underneath the umbrella of the Catholic Church were primarily independent city-states.   The printing press changed all of this. Suddenly Martin Luther, whose critique of the Catholic Church was strikingly similar to Jan Hus 100 years earlier, was not limited to spreading his beliefs to his local area (Prague in the case of Hus), but could rather see those beliefs spread throughout Europe; the nobility seized the opportunity to interpret the Bible in a way that suited their local interests, gradually shaking off the control of the Catholic Church.   Meanwhile, the economics of printing books was fundamentally different from the economics of copying by hand. The latter was purely an operational expense: output was strictly determined by the input of labor. The former, though, was mostly a capital expense: first, to construct the printing press, and second, to set the type for a book. The best way to pay for these significant up-front expenses was to produce as many copies of a particular book that could be sold.   How, then, to maximize the number of copies that could be sold? The answer was to print using the most widely used dialect of a particular language, which in turn incentivized people to adopt that dialect, standardizing language across Europe. That, by extension, deepened the affinities between city-states with shared languages, particularly over decades as a shared culture developed around books and later newspapers. This consolidation occurred at varying rates — England and France several hundred years before Germany and Italy — but in nearly every case the First Estate became not the clergy of the Catholic Church but a national monarch, even as the monarch gave up power to a new kind of meritocratic nobility epitomized by Burke.
 The culmination of this upheaval was the Peace of Westphalia, from whence we get the name Westphalian System; to quote Wikipedia: 
  The Westphalian system is the political order in international law that each state has exclusive sovereignty over its territory and are the monopolists of the ability to conduct warfare. The principle developed in Europe after the Peace of Westphalia in 1648, based on the state theory of Jean Bodin and the natural law teachings of Hugo Grotius. It underlies the modern international system of sovereign states and is enshrined in the United Nations Charter, which states that “nothing … shall authorize the United Nations to intervene in matters which are essentially within the domestic jurisdiction of any state.”
 The Westphalian system faces any number of challenges, from globalization to humanitarian interventions to the Internet. The E.U.’s attempts to regulate AI are a perfect example: given there are no borders on the Internet — outside the Great Firewall, anyways1 — the E.U. appears poised to hold American companies liable for models released on U.S. servers; in the case of Google, it has, for now, found it prudent to unilaterally not serve the E.U., lest it face the same challenges confronting OpenAI. This fight can, in a sense, be analogized to the Protestant and Catholic battles in Europe; in this case U.S. tech companies are the universal Internet, while Europe is seeking to protect its sovereignty. Or, perhaps, you prefer the opposite analogy, wherein Europe is seeking to export its beliefs to the rest of the world and, given the economic incentives towards having one product everywhere, very well may succeed (see cookie banners). The open source part, though, is distinct: open source models running locally might be a big boon to Apple, but they are the truly disruptive threat to centralized companies like Google and OpenAI. In other words, they are a third force, distinct from regulators and centralized operators; they are the Radical Reformation. This thought occurred to me while reading this fascinating thread from Owen Cyclops about American religion. It’s hard to find one single tweet to capture the thread, but Cyclops’ point is that the printing press led to three distinct religious groups: the Catholics, the Protestants, and then a whole host of fringe groups that were persecuted by both, and which, by extension, played a prominent role in American history. it kind of seems like america isnt a protestant country. america is a radical reformation country. — owen cyclops (@owenbroadcast) April 23, 2023   In this view the application of the printing press’s impact to the formation of modern Europe is incomplete; you also have to consider the fringe, which is to say the United States. And, by extension, if the digital transformation, from PC to Internet to AI, is of similar impact to the printing press, then the question at hand is not simply the nature of nation states going forward, but also the potential on the fringe. This is, admittedly, a rather speculative and far-reaching Article, particularly given I started with Google I/O. I think it is meaningful, though, that Google made clear it views AI as a sustaining innovation, and that it intends to fully implement generative AI across its business, including search. Of course that means there are battles to come within that context: the aggressiveness and competitiveness we’ve seen from these large tech companies is a refreshing change from the stasis of the previous decade. At the same time, the fact that all of Big Tech is on board and, given their supranational nature, will inevitably be incentivized to be a “helpful and engaged partner to regulators”, suggests that the true fight will be between centralized models and open source: the universal Catholic church and national religion Protestants had their conflicts, but they were unified in their disdain for the Anabaptists et al. In this view these proposed E.U. regulations are simply the first salvo in what may be the defining war of the digital era: will centralized — and thus controllable — entities win, or will there be a flowering on the fringe of open models that truly explore the potential of AI, for better or for worse. One surprising conclusion of these regulatory battles is that it is China which is arguably the greatest advocate for the Westphalian system today, and that the Great Firewall, while deleterious for Chinese freedom, may have been a gift in terms of Western freedom ↩ Loading