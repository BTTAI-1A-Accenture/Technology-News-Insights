Freedom of expression campaigners had said the original Online Safety Bill would mean social media platforms could censor content that was legal, but charities have said that was a good thing and the change was a "backward step". 
          Political reporter
              @alixculbertson
 Tuesday 29 November 2022 08:19, UK Social media sites will no longer have to take down material designated "legal but harmful" as part of the government's proposed plans for online safety. The Online Safety Bill will be amended and the controversial - but key - measure removed before it is set to go back to parliament next week after repeated delays. The government said it is making the changes over fears the original plans would have meant the biggest platforms would have had to not only remove illegal content, but also any material that had been named as legal but potentially harmful. Michelle Donelan, the culture secretary, said the bill in its current form "had a very, very concerning impact potentially on free speech". "There are unintended consequences associated with it," she told Sky News. "It was really the anchor that was preventing this bill from getting off the ground. It was a creation of a quasi-legal category between illegal and legal. That's not what a government should be doing." Free speech campaigners claimed governments or tech platforms could use the bill to censor certain content but charities and opposition parties said it was an important step in protecting children. 
                  How the sending of one photo led an 11-year-old girl to become a victim of physical sex abuse
                 
                  'It is too late, our boys have gone': Grieving parents tell Ofcom to 'step up' over social media content
                 
                  Tinder adds new 'Share My Date' safety feature to world's most used dating app 
                 Platforms will now be required to remove illegal content and any material that is in breach of their own terms of service. But instead of platforms removing legal but harmful duties, they will have to provide adults with tools to hide certain content they do not wish to see - including content that does not meet the criminal threshold but could be harmful, such as the glorification of eating disorders, misogyny and some other forms of abuse. The government is calling it a "triple-shield" of online protection that also allows freedom of speech. However, the Labour Party and the head of Samaritans have heavily criticised the amendment. Julie Bentley, chief executive of Samaritans, said removing the "legal but harmful" requirement was a "hugely backward step". "Of course, children should have the strongest protection but the damaging impact that this type of content has doesn't end on your 18th birthday," she said. "Increasing the controls that people have is no replacement for holding sites to account through the law and this feels very much like the government snatching defeat from the jaws of victory." Please use Chrome browser for a more accessible video player  Move will 'embolden abusers, COVID deniers and hoaxers' Shadow culture secretary Lucy Powell said it was a "major weakening" of the bill, adding: "Replacing the prevention of harm with an emphasis on free speech undermines the very purpose of this bill, and will embolden abusers, COVID deniers, hoaxers, who will feel encouraged to thrive online." Read more:Children coerced into most severe form of sexual abuse online, report finds The government will also update the bill to boost child online safety by strengthening accountability and transparency, it is understood. Tech firms will be required to publish summaries of risk assessments in regard to potential harm to children on their sites, show how they enforce user age limits and publish details of enforcement action taken against them by Ofcom, the sector's new regulator. Under the updated rules, platforms will also be prohibited from removing a user or account unless they have clearly broken the site's terms of service or the law. 'Young people will be safeguarded' Ms Donelan this morning insisted the bill had been "strengthened" for children, telling Sky News: "If the content is illegal, it has to go. If it's harmful but still legal, it has to go. And companies will face humongous fines if they breach these terms, up to 10% of their global turnover." She said companies will have to have proper age verification measures to stop children accessing adult content and "if they fail to do that, they could face the sanctions".  Speaking last night, she said of the bill: "Young people will be safeguarded, criminality stamped out and adults given control over what they see and engage with online. "We now have a binary choice: to get these measures into law and improve things or squabble in the status quo and leave more young lives at risk." Other updates to the bill were announced last week, including criminalising the encouragement of self-harm and of "downblousing" and the sharing of pornographic deepfakes. Further amendments will be tabled shortly aimed at boosting protections for women and girls online, the government confirmed. The Victim's Commissioner, Domestic Abuse Commissioner and Children's Commissioner will also be added as statutory consultees to the bill, meaning Ofcom must consult them with drafting new codes of conduct for tech firms so they are in compliance with the bill. Children's Commissioner for England, Dame Rachel de Souza, said this would ensure "children's views and experiences are fully understood" and added she is "determined to see this bill pass through parliament".