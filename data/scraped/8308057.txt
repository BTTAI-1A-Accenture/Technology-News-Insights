By  Jade Drummond, is a Brazilian journalist and strategy manager at Núcleo Jornalismo. She is a fellow at The Verge with the ICFJ Emerging Media Leaders Program. The arrival of generative artificial intelligence has accelerated the use of AI in different fields, including journalism. AI is most visible in journalism when things go wrong. Some newsrooms have published AI articles riddled with errors or offensive suggestions. There’s widespread anxiety that AI will be used to replace journalists on the cheap. But a new global survey demonstrates the ways that AI has worked its way into the business, even as journalists worry about its implications — and they don’t just involve writing articles.  The report was published this week by JournalismAI, an initiative from Polis, the London School of Economics and Political Science’s journalism think tank. It is supported by the Google News Initiative. “Generating Change: A global survey of what news organisations are doing with artificial intelligence” includes the perspective of “more than 120 editors, journalists, technologies and mediamakers from 105 small and large newsrooms across 46 countries.” JournalismAI doesn’t claim that the survey is representative of the whole global industry, but it does give a hint of how the media market is using these new technologies.  More than 75 percent of respondents used AI tools somewhere in the news process Among the respondents, more than 75 percent used AI somewhere in the chain of news gathering, production, and distribution. More than half mentioned increased efficiency and enhanced productivity as a reason to use it — ideally, AI can automate monotonous and repetitive tasks.  Around a third of respondents said they hoped AI technologies would help them reach a wider audience, personalize reader experiences, and enhance audience engagement.  At the same time, more than 60 percent of respondents were concerned about the ethical implications of AI integration in terms of editorial quality and other aspects of journalism such as accuracy, fairness, and transparency. Generally, newsrooms continue to view human intervention as crucial to mitigating the potential harms of AI systems, like bias and inaccuracy. Even as respondents worried that AI technologies could exacerbate biased news coverage and the misrepresentation of marginalized groups, few organizations provided solid examples of any potential solutions. The report says AI has particular pitfalls for newsrooms in the Global South. Most AI tools are developed with a focus on English (with very specific accents). Funds and resources are usually concentrated on a few countries, and different political realities might affect people’s trust in AI.  Nevertheless, the survey revealed that 90 percent of newsrooms are already using some form of AI in news production, 80 percent in news distribution, and 75 percent in news gathering. News gathering tasks include automated transcription and translation, extracting text from images, and scraping the web or using automated summarization tools. News production could include translating articles into other languages, proofreading, writing headlines, or writing full articles. Distribution includes using AI-driven search engine optimization as well as things like tailoring content to a specific audience. There are some huge differences in scale here — spell-checking an article with AI and using AI to generate a new article completely, for instance, hand over a very different level of control to AI tools. The report does not specify how many newsrooms are using this technology for each specific task, but it does mention that news distribution has the widest range of use cases, being most frequently mentioned as the area most impacted by AI in the newsroom.   Even though the majority of respondents are concerned about the implications of adopting AI tools, only around one-third of them said their organization had an AI strategy or were currently developing one. Tech companies like Google are building AI tools into their core businesses, even as they raise new ethical and legal concerns. Several newsrooms have blocked GPTBot, the web-crawling tool from Google competitor OpenAI, from using their data, and authors have sued OpenAI and Meta over using their work to train AI. However, news agencies have also struck deals with AI companies — like The Associated Press, which signed an agreement with OpenAI earlier this year.   / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly. The Verge is a vox media network © 2024 Vox Media, LLC. All Rights Reserved