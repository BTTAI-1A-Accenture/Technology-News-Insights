Earlier this week, Marc Zell, a representative for Republicans Overseas Israel, a U.S.-based political organization, shared a video on X that claimed to show a Hamas militant with a kidnapped Jewish girl taken to Gaza. “Hamas terrorist with kidnapped Jewish baby girl in Gaza. The caption in Arabic reads ‘ A lost girl’,” Zell posted. The clip has been viewed 1.1 million times and received almost 2,000 shares. But soon after it was posted to X, users pointed out that the video originated on TikTok and dates back to September. The original poster in turn deleted the video but it continues to circulate across social media. A Community Note—a crowd-sourced, fact-checking feature on the platform—has since appeared under Zell’s post that states “there is no indication” that the video, which was published before Hamas’ attack, shows a “‘Jewish girl’, that the child was kidnapped, that [the] video was shot in Gaza.”    The video is one of many examples of unverified, false, or misleading information swirling around on social media since Hamas launched a surprise, unprecedented attack against Israel on Oct. 7 that has left at least 1,300 people dead in the country. In Gaza, more than 1,400 Gazans have died from retaliatory Israeli airstrikes. Much of the graphic imagery and footage surfacing on social media depicts real and credible evidence of violence committed during the Israel-Hamas war. But experts say social media platforms have also been flooded with swaths of misinformation and disinformation, adding to the confusion about what is happening on the ground. It includes inaccurate claims and fabricated assertions, and the resurfacing of old and unrelated war footage or video game footage. “In times of general chaos and conflict, we do see a lot of disinformation and misinformation,” says Lisa Kaplan, founder of Alethea, a company tracking misinformation and disinformation. “This was true during the invasion of Ukraine, the withdrawal of troops from Afghanistan, and now, with the conflict between Israel and Hamas.” At least 14 false claims related to the war garnered 22 million views across X, TikTok, and Instagram within three days of the Hamas attack, according to confidential findings shared with TIME by NewsGuard, an organization that tracks misinformation.  The false spread of information is especially rife on X. In many instances, blue-check accounts, which users obtained by subscribing to the X’s premium service, boosted unsubstantiated claims. Soon after Hamas’ attack, for example, a digitally manipulated White House memo began circulating on X that the U.S. sent $8 billion in military aid to Israel. It gained traction after a post from @PunishDem1776, an X-verified account with 245,000 followers that NewsGaurd previously identified as a QAnon conspiracy theorist. (The U.S. on Thursday committed nearly $2 billion in military assistance to Israel.) In another example, one user shared footage claiming to show Hamas shooting down Israeli military helicopters—a video that was taken from the simulation video game “Arma 3.” Alethea, which is also tracking misinformation on the Israel-Hamas war, said the perpetrators included both profit-driven and politically-motivated actors. “We see commercial actors latching on to news coverage and playing both sides of the conflict to get things trending and to build a following for ads or spam campaigns,” Kaplan says. On the other hand, she says that politically motivated actors feel “extremely defensive” about their ideological position, which in turn causes them to engage in the spread false information. In some instances, users end up posting the wrong thing because “it matches preconceived narratives or its confirmation bias.”  X has undergone widespread changes since Elon Musk took ownership of Twitter, as the social media platform was known, in October 2022, including the loosening of content safety policies, cutting trust-and-safety employees, reinstating once-banned accounts, and introducing a premium service that allows users to pay for a verification badge. Experts say these changes have undermined users’ ability to determine which accounts are credible and to separate fact from fiction. During the early hours of Hamas’ surprise attack, Musk himself shared—and then deleted—an X post about “real-time” updates on the conflict that recommended X users follow two accounts previously known to spread false claims. “This is a perfect storm of disinformation caused by the proliferation of bad actors on an increasingly bad platform,” said Imran Ahmed from the Center for Countering Digital Hate, a  nonprofit that is being sued by X after it published research in June showing a rise in hate speech on the social platform under Musk's ownership. On Monday, X said that more than 50 million posts related to the Israel-Hamas war had been shared on the platform, adding that it had removed newly created accounts affiliated with Hamas, escalated “tens of thousands of posts” for sharing graphic media and hate speech to its content safety team, and updated its policies that defines what the platform considers “newsworthy.”   It has also pointed to Community Notes as a mechanism, which has since flagged some posts spreading false claims. But NewsGuard said it was still identifying unflagged posts that were garnering millions of views, likes, and reposts. (X did not respond to TIME’s request for comment.) European officials are now weighing in on the problem. On Thursday, the E.U. launched an investigation into X around the alleged "spreading of illegal content and disinformation, in particular the spreading of terrorist and violent content and hate speech." The announcements comes days after E.U. Commissioner Thierry Breton wrote a letter to Musk on Tuesday, which he shared on X, that read: “We have, from qualified sources, reports about potentially illegal content circulating on your service despite flags from relevant authorities.”  Write to Astha Rajvanshi at astha.rajvanshi@time.com