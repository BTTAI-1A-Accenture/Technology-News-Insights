Share For almost three decades, Google has been diligently doling out information on demand to netizens about anything and everything under the Sun â€” and all this in real time. The curiosity market has experienced a paradigm shift since the rise of AI tools generating content for and on behalf of humans. While Google has long preached â€˜helpful content written by people, for people, in search resultsâ€™, its recent actions indicate otherwise.Â  Behind the usersâ€™ back, the company quietly rewrote its own rules to acknowledge the rise of AI-generated content on the internet. In the latest iteration of the companyâ€™s â€˜Helpful Content Updateâ€™, the phrase â€œwritten by peopleâ€ has been replaced by a statement that search giant is constantly monitoring â€œcontent created for peopleâ€ to rank sites on its search engine. The linguistic pivot shows that the company does recognise the significant impact AI tools have on content creation. Despite prior declarations of intentions to distinguish between AI and human-authored content, with this move, it appears that the company is contradicting its own stance on the omnipresent AI-generated material on the internet.Â  Yesterday, 404 Mediaâ€™s Emanuel Maiberg pointed out that the first picture that pops up if you search â€œtank manâ€ on Google is not the iconic picture of the unidentified Chinese man who stood in protest in front of the tanks leaving the Tiananmen Square anymore, but a fake, AI-generated selfie of the history. Since AI-powered tools hallucinating is hardly a novel concept, the fact that these models also make up stuff is inevitable. While these chatbots rehash content on the internet, the possibility of them churning out false information is imaginable. Hence, in the near future, AI bots double-checking â€œfactsâ€ on the basis of their own previously generated content doesnâ€™t look like a good idea.Â  Google is one of the leading contributors to fight this phenomenon. At the I/O conference, the companyâ€™s executives announced plans to take significant steps to identify and contextualise AI content available on its Search. While measures like watermarking and implementing metadata aims to ensure transparency and enable users to differentiate between AI-generated and authentic images, it can only be applied to images as there is no obvious way to watermark AI-generated text. Owning its messiah complex, yesterday, Google introduced a bunch of notable features to its AI chatbot Bard, including a way to cross-reference its answers through the â€œGoogle itâ€ button. The button, which previously let users explore topics related to Bardâ€™s answer on Google, now evaluates whether Bardâ€™s answers align with or contradict information found through Google Search. Even more concerning is Bardâ€™s newfound responsibility to fact-check its own AI-generated outputs using Googleâ€™s search results â€” reducing the chances of the response being error-free.Â  While Google is busy updating its â€œtransparentâ€ policies behind closed doors, allowing Search to be flooded with unfiltered AI data, in future AI models including Bard are going to be trained on this data. Hence, the risk of unfiltered spam datasets to train these models increases. As the boundaries of AI replication blurs, the looming question is, what happens when AI-generated content proliferates across the internet, becoming the primary source for AI model training? The ominous answer â€” an impending digital collapse. Google issued a statement in the recent past asserting its commitment to fortifying Search results against spam, emphasising that employing AI-generated content to manipulate Search rankings is a violation of spam policies within Alphabet. But, the latest updates tell a different tale.Â  Standards continue to evolve as AI proliferates. For now, Google appears steadfast in pushing forward the AI advancements by every means possible â€” be it by updating policies or adding features to Bard, the companyâ€™s sole representative against OpenAIâ€™s ChatGPT.Â  The company seems to be grappling with the duality of AI-generated content, caught between championing its potential and safeguarding its search results. While Google is navigating the slippery slope, the companyâ€™s moves hold the potential to make or mar the future AI-infused digital frontier.Â  ğŸ“£ Want to advertise in AIM? Book here Chief minister Siddaramaiah announced Project Cheetah, another Foxconn facility for the manufacture and assembly of EV components, adding to the list of Karnataka Foxconn projects after Project Elephant. Discover how Cypher 2024 expands to the USA, bridging AI innovation gaps and tackling the challenges of enterprise AI adoption Email:info@aimmediahouse.com Our Offices AIM India#280, 2nd floor, 5th Main, 15 A cross, Sector 6, HSR layout Bengaluru, Karnataka 560102 AIM Americas99 South Almaden Blvd. Suite 600 San Jose California 95113 USA Â© Analytics India Magazine Pvt Ltd & AIM Media House LLC 2024