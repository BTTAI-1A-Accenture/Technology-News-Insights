When an AI-generated image of an explosion occurring outside the Pentagon proliferated on social media earlier this week, it provided a brief preview of a digital information disaster AI researchers have warned against for years. The image was clearly fabricated, but that didn’t stop several prominent accounts like Russian state-controlled RT and Bloomberg news impersonator @BloombergFeed from running with it. Local police reportedly received frantic communications from people believing another 911-style attack was underway. The ensuing chaos sent a brief shockwave through the stock market. The deepfaked Pentagon fiasco resolved itself in a few hours, but it could have been much worse. Earlier this year, computer scientist Geoffrey Hinton, referred to by some as the “Godfather of AI,” said he was concerned the increasingly convincing quality of AI-generated images could lead the average person to “not be able to know what is true anyone.” Startups and established AI firms alike are racing to develop new AI deepfake detection tools to prevent that reality from happening. Some of these efforts have been underway for years but the sudden explosion of generative AI into the mainstream consciousness by OpenAI’sDALL-E and ChatGPT has led to an increased sense of urgency, and larger amounts of investment, to develop some way to easily detect AI falsehoods. Companies racing to find detection solutions are doing so across all levels of content. Some, like startup Optic and Intel’s FakeCatch, are focusing on sussing out AI involvement in audio and videos while others like Fictitious.AI are focusing thier efforts more squarely on text generated by AI chatbots. In some cases, these current detection systems seem to perform well, but tech safety experts like former Google Trust and Saftey Lead Arjun Narayan fear the tools are still playing catch up. “This is where the trust and safety industry needs to catch up on how we detect synthetic media versus non-synthetic media,” Narayan told Gizmodo in an interview. “I think detection technology will probably catch up as AI advances but this is an area that requires more investment and more exploration.” Here are some of the companies leading the race to detect deepfakes. 
          An attempt to influence the U.S. presidential election harnessed ChatGPT to generate stories and social media comments, per OpenAI.
         
          MAGA fans somehow find new ways to prove how weird they are every day.
         
          Russell Vought also says that he supports "Christian nation-ism" and wants America to do away with "multiculturalism."
         
          Support for Democrats Rep. Ruben Gallego in Arizona and Rep. Elissa Slotkin in Michigan has raised eyebrows.
         
          Buying followers or bots to artificially inflate social media stats is also prohibited.
         
          Pixel Screenshots app will let you categorize, search through, and add notes to your screenshots. Best of all, it's not auto-screenshotting everything on your phone.

         We may earn a commission when you buy through links on our sites.
©2024 GIZMODO USA LLC. All rights reserved. Mode 
                Follow us
               Mode 
                Follow us
              