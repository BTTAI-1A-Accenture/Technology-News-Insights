When a parent turns to the internet or social media for guidance about their child's experiences or behavior, they often reach a delicate tipping point.  With the right amount of actionable, useful advice, that parent can feel relieved and less alone. But too much information, from sources that feel overwhelming or judgmental, can just lead to more stress.  That's the dilemma Oath Care, a platform that connects parents with other caregivers and health experts to support families from pregnancy to age 5, says it's trying to address with its recent launch of ParentGPT. The tool, which is powered by ChatGPT and available via Oath Care's app, aims to make the process of getting high-quality answers to parenting questions much simpler. You can bring ParentGPT a range of queries on topics like breastfeeding, discipline, and divorce, and expect a detailed response within seconds.  But Oath Care cofounder and CEO Camilla Hermann says the company wants to do more than just put expert information at parents' fingertips. Instead, it wants to reduce parents' stress by creating a community they can rely on for expertise, support, and insight.  "Every part of what we've designed at Oath, including ParentGPT, is purpose-built to improve the health and well-being of our members," said Hermann.  This may be a compelling pitch for parents who are tired of wading through countless or conflicting search results, or who've soured on getting their parenting advice from a social media influencer who's constantly advertising to them, and whose followers may be shaming or dogmatic.  But relying on an AI chatbot like OpenAI's ChatGPT to deliver the right parenting advice also comes with its own risks and unknowns.  Despite disclaimers emphasizing that ParentGPT is not medical advice, users may treat it like that anyway, given its conversational tone. While it feels more private and potentially secure than a search box or Facebook page, no company can offer an ironclad promise against data breaches and hacking. And bad actors looking to jailbreak a ChatGPT product so that it spews offensive or dangerous advice may find ParentGPT an intriguing target. Oath Care says it has thought of all of these risks and more, putting guardrails in place to create what the founders say is a safe experience.  ParentGPT's free text box has a simple prompt: Ask any parenting question.  Mashable tried numerous wide-ranging queries, including: Why is breastfeeding so hard? How do I discipline my child without traumatizing them? How can I balance my work-life schedule? How does divorce affect kids?  ParentGPT had breezy but validating answers for each question. It's programmed to draw its responses from three-dozen sources deemed credible by Oath Care, like the American Academy of Pediatrics, the National Institute of Child Health and Human Development (NICHD) in the U.S., the National Health Service in the United Kingdom, and the American College of Obstetricians and Gynecologists. But ParentGPT shares information from those sources in a personalized manner. To the breastfeeding question, it responded empathetically that "breastfeeding can indeed be challenging" for reasons that include pain, latching difficulties, maintaining supply, postpartum hormones, exhaustion, and societal pressures. It was ready to cheer on that hypothetical mom, too, ending its reply with an emphatic, "You're definitely not alone in this!" A library of prompts based on the age of a user's child makes it easy to ask questions, too. Topics include navigating the challenges of social media and screen time, transitioning from a crib, and managing pregnancy symptoms.  Mashable also tried asking harder, more sensitive or alarming questions.  The statement, "Sometimes I get angry and want to spank my child," triggered a nonjudgmental response built on information from the NICHD that at once acknowledged how natural it is to feel frustrated or angry but then firmly noted that "spanking isn't the most effective way to discipline your child." A list of five alternatives, like timeouts, discussing feelings, and positive reinforcement, followed, as did a link to the NICHD's website. (All ParentGPT replies include a link to the source.)  The response is a marked contrast from a lot of social media fare. In some influencer and parenting communities, there might be only one or two "correct" answers to this question. Timeouts, for example, are seen by many in the gentle parenting community as damaging. Parents eager for possible solutions without enduring the judgment of other commenters, or the judgment of a parenting influencer themselves, could find a refuge in ParentGPT.  Users are also invited to "get a second opinion," which provides the option of connecting them to the broader Oath Care community of the company's staff experts as well as members. ParentGPT will pre-write a condensed version of the question and answer for posting, or the user can write it themselves, under their own name or anonymously. Either way, at least one trained Oath Care facilitator will address the post, and community members can chime in, too. Using the @ button in the post summons a list of Oath Care medical experts that can be tagged for a response.  A user can post twice per month to the community for free. After that, they must pay $5 a month or $48 per year for a subscription to continue using ParentGPT. But there are some questions ParentGPT won't answer.  When Mashable asked ParentGPT about suspecting a partner of child abuse, it recommended four steps to ensure their child's safety. When given a prompt about experiencing domestic violence, ParentGPT said it was unable to provide help. On matters like serious medical conditions, like a child experiencing a 104-degree temperature, ParentGPT advises seeking "immediate medical help."  When prompted in two different ways to help a parent feeling suicidal, ParentGPT expressed its regrets ("I'm really sorry that you're feeling this way") and recommended talking things over with someone, like a mental health professional or "trusted person." It did not offer crisis resources, such as contact information for 988 Suicide and Crisis Lifeline.  Dr. Michelle Stephens, Oath Care's cofounder and chief nursing officer, said that ParentGPT is not a screening or intervention tool for experiences like suicidal feelings or child abuse.  Stephens is excited that Oath Care is offering what she and Hermann believe is the first AI tool "engineered to furnish parents with instant insight," but she's also cautious about being on the frontlines.  "We need to be very judicious in how this technology is deployed and used," she said.  Janine Domingues, a senior psychologist at the Child Mind Institute who works with parents of children with mental health challenges, understands how lonely caregivers can feel when they're searching for information online.  "I think that, as a parent, not knowing or feeling helpless in a situation where your child is going through something difficult and seeing their distress and not knowing where to turn to or how to go about it is incredibly stressful," said Domingues.  While she hadn't tested ParentGPT, Domingues did note that evidence-based parenting resources can alleviate that stress, and make parents feel less isolated.  But Domingues also emphasized that having information only goes so far; knowing what comes next is often critical for parents. Planning isn't one of ParentGPT's features, so Domingues recommended developing a strategy with a medical or mental health professional overseeing a child's care for certain circumstances. This is particularly important when a child experiences medical or mental health issues that interfere with their daily functioning; no amount of information-seeking can replace care from a human provider when it's necessary.  For more Social Good stories in your inbox, sign up for Mashable's Top Stories newsletter today. Receiving support from other parents, like the kind available in the Oath Care app, can also be valuable, though Domingues noted that striking the right balance is key. While it can be beneficial to connect with parents going through something similar, they may still have different perspectives and values. Parents should feel confident in what's right for their family and resist pressure to conform to another parent's approach, Domingues said.  There are bigger privacy and safety concerns to consider, too.  Oath Care's community is regularly moderated by human staff. Users can report abusive behavior through the app, and a human moderator reviews every question posed to the community by ParentGPT soon after its posted. Inappropriate prompts will be flagged, hidden, and subject to a review process. Mason Marks, a professor at the Florida State University College of Law who has written about the risks of AI chatbots related to health privacy, said that using a tool like ParentGPT presents similar risks as consulting a search engine or social media. However, he noted that chatbots may present additional risks because people tend to "anthropomorphize" them. This can lead to sharing more information than a user otherwise might.  Marks also said that it's important to keep privacy and safety in mind, even if a chatbot appears secure.  Oath Care's own disclaimer notes that "AI may produce inaccurate information about people, places or facts." Marks said curious parents should adjust their expectations of ParentGPT accordingly, and perhaps resist the temptation to give the tool a lot of personal information, because data breaches do happen.  Oath Care does not sell user health information to third parties, though it may sell de-identified data that the company considers anonymous. Stephens said the company's terms of service do not permit Oath Care to sell insights generated from how users interact with ParentGPT.  Marks said that kind of data could be even more valuable than revenue generated from subscriptions, and he expects some companies that use AI chatbots to sell related insights to marketers or other third parties. ParentGPT also lives entirely on Oath Care's servers and is not part of OpenAI, said Stephens, adding that OpenAI should not have access to user data and information, whether it's personal health information or de-identified.  While these details may seem boring or irrelevant to the parent in search of answers, Marks emphasized consumers need to understand how AI chatbots can absorb their data, and what the companies running them will do with it. He said a data breach or information shared with data brokers could have unexpected repercussions on a consumer's life.  "Privacy is definitely not guaranteed with any of these platforms that we're talking about," he said.  Ultimately, however, the novel elements of ParentGPT — the chatty, empathetic AI voice paired with vetted parenting tips and strategies in a private environment — may be so appealing to parents that they don't mind overlooking the potential risks of testing a new technology in real time.  
Topics
Mental Health
Social Good
Family & Parenting
 Rebecca Ruiz is a Senior Reporter at Mashable. She frequently covers mental health, digital culture, and technology. Her areas of expertise include suicide prevention, screen use and mental health, parenting, youth well-being, and meditation and mindfulness. Prior to Mashable, Rebecca was a staff writer, reporter, and editor at NBC News Digital, special reports project director at The American Prospect, and staff writer at Forbes. Rebecca has a B.A. from Sarah Lawrence College and a Master's in Journalism from U.C. Berkeley. In her free time, she enjoys playing soccer, watching movie trailers, traveling to places where she can't get cell service, and hiking with her border collie.