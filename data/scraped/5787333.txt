FILE - This combination of images shows logos for companies from left, Twitter, YouTube and ... [+] Facebook. Russia's invasion of Ukraine is forcing big tech companies to decide how to handle state-controlled media outlets that spread propaganda and misinformation on behalf of the invaders. (AP Photo/File) Social media platforms like Meta, YouTube, X (formerly Twitter) and TikTok are facing intense scrutiny after an EU report revealed their failure to constrain a massive Kremlin disinformation campaign surrounding Russia's invasion of Ukraine. The study, conducted by civil society groups and published last week by the European Commission, found that "the reach and influence of Kremlin-backed accounts has grown further in the first half of 2023, driven in particular by the dismantling of Twitter's safety standards." Across major platforms, pro-Kremlin accounts now have over 165 million subscribers and generated an astounding 16 billion views since February 2022. The report slams Big Tech's haphazard response, saying policies were applied sporadically at best. Content moderation failed to address coordinated disinformation campaigns tailored across platforms. Rules varied wildly across services, letting actors exploit inconsistencies. "In absolute numbers, pro-Kremlin accounts continue to reach the largest audiences on Meta’s platforms. However, their audiences only grew marginally on Facebook and Instagram compared to other platforms. The subscriber numbers of pro-Kremlin channels more than tripled on Telegram since the start of the war, more than doubled on TikTok and rose by almost 90 percent on YouTube," researchers pointed out. Most damning is the rapid growth of hate and lies on X after Elon Musk acquired the company last October. Between January and May 2023, engagement grew by 36 percent after the new owner decided to lift mitigation measures on Kremlin-backed accounts and removed labels from Russian state-affiliated accounts, arguing that “all news is to some degree propaganda.” Researchers warn the Kremlin's sophisticated information warfare threatens free and fair elections and fundamental human rights across the EU. With European parliamentary elections approaching in 2024, platforms must act swiftly to comply with the new EU digital regulation that went into effect on August 25th, the Digital Services Act, before it is too late. In accordance with DSA guidelines, all large social media companies and search engines with a user base of at least 45 million monthly active users in the EU are now required to adopt a more rigorous approach to content moderation, proactively clamping down on disinformation and hate speech, or face heavy fines. Under the new law, these companies are required to gauge the risk of fake news spreading across their platforms, stop the amplication of harmful content and face regular audits to measure the success of their efforts. Would the study’s result have been different, if the new regulation had already been in place? Researchers believe so. "The rules provided by the DSA hold great potential to reign in Kremlin disinformation campaigns and other state-sponsored attacks on the democratic integrity and fundamental rights," the study urged. "But they must be applied quickly and effectively in order to help mitigate these coordinated attacks on European democracy." It’s worth noting though, that Telegram, which the report identifies as one of the main channels used to spread Russian propaganda, does not have to comply with the Digital Services Act, as it currently reports only 33 million monthly active users in the EU. 