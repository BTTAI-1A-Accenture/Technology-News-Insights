When it comes to next-level image editing, wouldn’t it be great if you could take a decent smartphone photo, tell your device to “make this photo look like a pro took it,” and a few seconds later end up with something you can frame, hang on your wall, and make everyone who sees it will think you’re a visual genius?  That’s where Adobe’s headed with its next new thing, Firefly-infused Photoshop Generative Fill AI. Firefly, Adobe’s new artificial intelligence factory, rolled out six weeks ago. Now it’s adding new features in Photoshop, one of the most popular graphics and photo editing software on the market. I took a tour of the new AI tools in Photoshop just prior to its recent launch. The standout feature for me is the ability to highlight or “lasso” an area in a photo, then click on a new “Generate” icon, type a few keywords to describe exactly what you want to see replace your selection, and it appears like magic.  For instance, take a look at the photo of the reindeer in a forest below. With the new generative fill integration, you can isolate a deer, tap “Generate,” and type in a prompt like “wet alley at night.” You can even layer in a vintage red arrow sign for added drama. This is just one example John Metzger, Adobe’s director of product management for Photoshop demonstrated over the video call.  AI phone scams:The call is coming from inside the internet: AI voice scams on the rise with cloning tech Find unclaimed money:You may have money coming to you. Where to look for unclaimed accounts that belongs to you. Hackers using AI:Hackers are using AI to crack passwords: How to choose better passwords to keep them out Its other new AI generative fill trick gives you a way to remove objects without weird glitches in the result. Before, you could erase a person, or in the example below, a surfboard, but you’re left with strange smears that you have to fix where that person or object used to be. In the beach example below, Firefly AI takes the board out and fills in the rail, sky, sand, and even shadow in ways that make it impossible to see your alterations. This is a tool most content creators use daily, and I haven’t worked with one that’s this easy and fast before.  Another standout feature overall is how this new generative fill matches perspective, lighting, and image style better than we’ve seen with a myriad of other tools. It allows you to make changes in layers, so you’re not messing with your original or married-to change you might want to break up with later.  I’ve been playing around with similar beta AI ideas in Canva and other apps, such as Magic Eraser Background, and as you might expect, they don’t do as well against a heavyweight like Photoshop. You can try these new features free for seven days online, then it’s $21/month for Photoshop or $55/month for Adobe’s entire suite of Creative Cloud apps. You can also try it for free using Firefly beta.  Don’t expect perfection yet with Photoshop, either. As mentioned, this generative fill tool is available in Firefly and Photoshop in beta − still in the testing − phase. It struggles with human hands and facial features, the same as we’ve seen across all AI image makers, including Midjourney, Dall-E2 and others. That’s no surprise since Adobe’s using a similar AI image generation technique called diffusion, which others like Dall-E, Midjourney, Stable Diffusion, and Google’s Imagen use as well. While it hasn’t said “when” yet, Adobe plans deeper AI integration across its other apps like Illustrator and Premiere too. Yep, that means it’s coming to video editing, which is equal parts exciting and terrifying. AI-generated fake images make the rounds on social media and so-called “news” sites every day. Remember the Pope in a puffy jacket? Or even in May, when that fake news report on Twitter supposedly showed an explosion near the Pentagon?  Ashley Still, the senior vice president of Digital Media at Adobe told me that they’ve built in an array of guard rails to make sure people don’t use Firefly AI to create deep fakes. Adobe now embeds metadata into every creation, including attribution, provenance, and what role AI played in making the finished image.  “We think of it like a nutrition label for (content),” Still explained. “This kind of transparent metadata applied to each file is the only way to trust or even understand the superpower of AI generative fill and what it enables,” she added.  Adobe’s Content Authenticity Initiative outlines the transparency tools and has a verification checker you can use to test whether a photo’s fake too.  The other big issue around AI artwork is how often it uses images scraped from the internet without attribution, leaving photographers, designers, and creatives empty-handed when someone else uses their work. Adobe says they thought of that too.  “Our models train only on IP we have the explicit license to use,” Still said. “We use content from Adobe Stock’s hundreds of millions of professional-grade, licensed images. We do not use other peoples’ or brands’ intellectual property. In addition, Adobe is developing a compensation model for Adobe Stock contributors and will share details once (Adobe Firefly) is out of beta.” When it comes to next-level image editing, I want a tech tool that can take any number of my “almost, but not quite, perfect” iPhone photos and instantly make them look like a pro shot and edited them.  Firefly’s AI is not there yet, nor is that its purpose. It’s a tool to make the process faster, more intuitive, and let more people like me dabble in creativity. The actual secret sauce to the photos I have framed on my walls though − is still the human touch −and that’s not going away anytime soon. Jennifer Jolly is an Emmy Award-winning consumer tech columnist. The views and opinions expressed in this column are the author's and do not necessarily reflect those of USA TODAY.