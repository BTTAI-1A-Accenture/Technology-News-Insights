Generative AI could soon be trained on AI-generated content — and experts are raising the alarm. The phenomenon, which some experts call "model collapse," could result in AI producing low-quality outputs down the line. The new term comes as AI-generated content filled with errors continues to flood the internet. Experts warn that AI-generated content may pose a threat to the AI technology that produced it. In a recent paper on how generative AI tools like ChatGPT are trained, a team of AI researchers from schools like the University of Oxford and the University of Cambridge found that the large language models behind the technology may potentially be trained on other AI-generated content as it continues to spread in droves across the internet — a phenomenon they coined as "model collapse." In turn, the researchers claim that generative AI tools may respond to user queries with lower-quality outputs, as their models become more widely trained on "synthetic data" instead of the human-made content that make their responses unique. Other AI researchers have coined their own terms to describe the training method. In a paper released in July, researchers from Stanford and Rice universities called this phenomenon the "Model Autography Disorder," in which the "self-consuming" loop of AI training itself on content generated by other AI could result in generative AI tools "doomed" to have their "quality" and "diversity" of images and text generated falter. Jathan Sadowski, a senior fellow at the Emerging Technologies Research Lab in Australia who researches AI, called this phenomenon "Habsburg AI," arguing that AI systems heavily trained on outputs of other generative AI tools can create "inbred mutant" responses that contain "exaggerated, grotesque features." While the specific effects of these phenomena are still unclear, some tech experts believe that "model collapse" and AI inbreeding could make it difficult to pinpoint the original source of information an AI-model is trained on. As a result, providers of accurate information such as the media may decide to limit the content they post online — even putting it behind paywalls — to prevent their content from being used to train AI, which could create a "dark ages of public information," according to an essay written by Ray Wang, the CEO of tech research firm Constellation Research. Some tech experts are less worried about the growth of AI-generated content on the internet. Saurabh Baji, the senior VP of engineering at AI-firm Cohere, told Axios that human guidance is "still critical to the success and quality" of its AI-generated models, and others told the outlet that the rise of AI-generated content will only make human-crafted content more valuable. These new terms come as AI-generated content has flooded the internet since OpenAI launched ChatGPT last November. As of August 28, NewsGuard, a company that rates the reliability of news websites, identified 452 "unreliable AI-generated news outlets with little to no human oversight" that contain stories filled with errors. AI-generated sites with generic names like iBusiness Day, Ireland Top News, and Daily Time Update may appeal to consumers as accurate sources of information, which would bolster the spread of misinformation, according to NewsGuard. It's not just AI-generated websites that have produced articles filled with inaccuracies. In January, tech publication CNET published 77 articles using an "internally designed AI engine" and had to issue significant corrections after learning that its articles were riddled with basic math errors. Months later, Gizmodo criticized company executives after the media outlet published AI-written articles with factual inaccuracies. Most recently, Microsoft removed a string of articles from its travel blog, one of which was found to be an AI-generated article recommending visitors in Ottawa to visit the Ottawa Food Bank and to "consider going into it on an empty stomach." Now that AI-content detectors like ZeroGPT and OpenAI's Text Classifier have been found to be unreliable, people may find it harder to discover accurate information with human oversight online, Kai-Cheng Yang, a computational social science researcher who has written a paper about the malicious actors that could take advantage of OpenAI's chatbot, previously told Insider. "The advancement of AI tools will distort the idea of online information permanently," Yang said Read the original article on Business Insider New Orleans Pelicans star Zion Williamson appears to have lost notable weight during the offseason, based on photos taken at his basketball camp in South Carolina. Michael Penix Jr. is done for the preseason, Raheem Morris said. Mike Tyson had little interest in trash-talking or insulting Jake Paul during the press conference for their Nov. 15 fight on Netflix. Friday’s collapse marks the seventh home to be swept into the ocean in the last four years. The stylish star went big on black and white for her collection of dishes, decor and more with housewares brand Hudson Grace. Russell Wilson got his first preseason start after being held out last week. In the long-running "Alien" movie franchise, the Weyland-Yutani Corporation can’t seem to let go of a terrible idea: It keeps trying to make a profit from xenomorphs -- creatures with acid for blood and a penchant for violently bursting out of human hosts.  Sadly, as much as I liked “Alien: Romulus” (and I liked it a lot!), the new sequel (or "interquel") can’t escape a terrible idea of its own: Hollywood’s fixation on using CGI to de-age or resurrect beloved actors.  “Alien: Romulus” tries to pull off a similar trick — while it doesn't resurrect the exact same murderous android from the original “Alien,” it features an identical model, seemingly played by the same actor, Ian Holm, who died in 2020. Who will take over coaching Team USA for the Los Angeles Olympics? iSeeCars' latest analysis found that a handful of models have a much greater chance of lasting 250,000 miles than others. Rocket Lab CEO Peter Beck sees the company's Neutron rocket as "the last piece of the puzzle" in its ongoing quest to build out an end-to-end space company. He says it's also poised to threaten the lead Elon Musk's SpaceX has in the market. These are today's mortgage and refinance rates. Rates have been inching up for a few days, but they're actually lower than last week. Lock in your rate today. There are a lot of myths out there when it comes to washing your hair. It's time to set the record straight. A handy Yahoo News guide to the 2024 map. Right before the 2024 season starts this Saturday, Dan Wetzel, Ross Dellenger and Pat Forde start the season on a positive note: by discussing which head coaches will get fired first. They inspect the hot seat situations for top names like Florida's Billy Napier, Baylor's Dave Aranda, and Arkansas' Sam Pittman. With flag football making its Olympic debut in LA 2028, Team USA QB Darrell Doucette says NFL player won't be able to join the roster without a fight. Jake Mintz & Jordan Shusterman talk about if the D-backs or Padres can catch the Dodgers in the NL West after their hot streak, the Astros doing typical Astros things and how realistic a 6 innings starter mandatory rule might be. Bloomquist was one of the most successful dirt Late Model drivers ever. Muscles rather than high octane fuel will be powering the action next August 2 at the Bristol Motor Speedway when humans without machines — members of the Cincinnati Reds and the Atlanta Braves — gather for a regularly scheduled baseball game. While skepticism about Elliott’s explosiveness and perhaps his gross production is warranted, the Cowboys view Elliott’s role in their ecosystem more favorably than the broader public. While blue moons might not be as rare as their name implies, the next super blue moon won’t be seen until 2037.