Pembroke, MA - September 15: A bumblebee gathers nectar from a Mexican sunflower. (Photo by John ... [+] Tlumacki/The Boston Globe via Getty Images) Databases are changing. They’re changing because they are always getting bigger and more scalable, they’re changing because storage techniques and processing power is always developing and they’re changing because we are applying new platform-level sea-change computing principles to them when they come around and shake up our IT universe - which (as a general rule of thumb if you’re tracking the next big thing) is often roughly every five years. While the drive to make data services increasingly cloud-native and more closely aligned to suit multi-cloud deployment so that organizations can take their pick from the major Cloud Service Provider (CSP) hyperscalers is often lauded as the key driver for database change, a more complex - no, let’s say more powerful - technology trend is also surfacing. This is the age of the vector database and the industry’s major data vendors are busily engineering their core platform offerings to deliver this core function. Vocal on this topic this month is DataStax. Now styling itself as a ‘real-time AI company’ in the way that database vendors who want to be seen as hip and connected do, DataStax has now delivered a vector search capability in Astra DB, its Database-as-a-Service (DBaaS) technology built on Apache Cassandra, a popular open source NoSQL database. Although this question has been put before, let’s make sure we really understand what a vector database actually is in full - and in simple terms too. A database that supports vector search can store data as ‘vector embeddings’, an essential way of working if we are to deliver generative AI applications like those built on GPT-4. That’s nice (and factually correct too), but it doesn’t explain what these embeddings do. Vector embeddings are mathematical representations of objects or data points that exist in a multi-dimensional space, where each dimension corresponds to a specific feature or attribute that we ultimately use to describe the object. But can we explain objects in simpler terms? If an airline passenger travels from Salt Lake City to London, has a nut allergy, watches three in-flight movies and eats a chicken meal while in the air, then we could combine all those behavioral vectors, treat them as data points rather than human actions and encode then encode the mathematical values into our object. In this case, let’s call that object Arthur Jackson’s Utah flight experience. A vector database is a type of database that is specifically designed to store and query high-dimensional vectors, so we could also combine Mr Jackson’s age, frequent flyer status and hundreds of other factors if we wanted to. “Vector embeddings are the data representation that AI models (such as Large Language Models, or LLMs) use and generate to make complex decisions. Like memories in the human brain there is complexity, dimension, patterns and relationships that all need to be stored and represented as part of the underlying structures which makes all of this difficult to manage,” notes DataStax, on its explanatory web pages on this subject. For an appealing extra slice of learning here, let’s also mention the term Approximate Nearest Neighbor or ANN. This is the algorithm that we can use to find similar things in vector embeddings. We use ANN to look for items that are mathematically similar, based on how a computer classifies them. If we are looking for pictures of bees on flowers, then we want to find images that include the embedding for [bee], [flower], [yellow] etc. The ANN search finds those entries in the data that match this the closest. Back to DataStax then, the company has rolled out its new vector database power in line with also offering new availability on Microsoft Azure and Amazon Web Services (AWS), adding to initial availability on Google Cloud. Remember how we said multi-cloud capabilities was key at the start here? Well, that’s happening here too, clearly. The company says that vector search will be available for customers running DataStax Enterprise, an on-premises (i.e. not in a public cloud) self-managed offering. Recent integration of Astra DB into the open source framework LangChain is hoped to continue to accelerate the adoption of generative AI for users here. "Every company is looking for how they can turn the promise and potential of generative AI into a sustainable business initiative. Databases that support vectors – the ‘language’ of Large Learning Models (LLMs) – are crucial to making this happen,” said Ed Anuff, chief product officer, DataStax. “Enterprises looking to participate in the AI ecosystem require a vector database to power AI applications with their proprietary data to offer their customers and stakeholders a dynamic and compelling user experience through the transformative impact of generative AI. Anuff further suggests that an enterprise will need trillions of vectors for generative AI so vector databases must deliver limitless horizontal scale. He claims that Astra DB is the ‘only vector database on the market’ today that can support massive-scale AI projects, with enterprise-grade security and on any cloud platform. “We are at the very early stages of identifying enterprise use-cases for generative AI but expect adoption to grow rapidly and assert that through 2025, one-quarter of organizations will deploy generative AI embedded in one or more software applications,” said Matt Aslett, VP and research director, Ventana Research. “The ability to trust the output of generative AI models will be critical to adoption by enterprises. The addition of vector embeddings and vector search to existing data platforms enables organizations to augment generic models with enterprise information and data, reducing concerns about accuracy and trust.” While we wait for every enterpise data vendor to deliver on generative AI, to team with all three major cloud hyperscalers, to encompass the universe of ancilliary-yet-core database technologies driving current trends (such as data lakehouse capabilities, connectivity to data marketplaces or exchanges and the ability to handle multiple transactions simultaneously, often in real-time) and to add as many new tiers of automation and autonomous management as possible, we can take stock and see that there is much still to do. There is certainly nectar in vector, let's bee-hold it (sorry).  One Community. Many Voices. Create a free account to share your thoughts.  Our community is about connecting people through open and thoughtful conversations. We want our readers to share their views and exchange ideas and facts in a safe space. In order to do so, please follow the posting rules in our site's Terms of Service.  We've summarized some of those key rules below. Simply put, keep it civil. Your post will be rejected if we notice that it seems to contain: User accounts will be blocked if we notice or believe that users are engaged in: So, how can you be a power user? Thanks for reading our community guidelines.  Please read the full list of posting rules found in our site's Terms of Service.