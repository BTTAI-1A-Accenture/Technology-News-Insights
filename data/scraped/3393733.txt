Fitness advice from OpenAI’s large language model is impressively presented—but don’t take it too seriously. When I opened the email telling me I’d been accepted to run the London Marathon, I felt elated. And then terrified. Barely six months on from my last marathon, I knew how dedicated I’d have to be to keep running day after day, week after week, month after month, through rain, cold, tiredness, grumpiness, and hangovers.  What no one warns you is that the marathon is the easy part. It’s the constant grind of the training that kills you—and finding ways to keep it fresh and interesting is part of the challenge.  Some exercise nuts think they’ve found a way to do that: by using the AI chatbot ChatGPT as a sort of proxy personal trainer. Created by OpenAI, it can be coaxed to churn out everything from love poems to legal documents. Now these athletes are using it to make all the relentless running more fun. Some entrepreneurs are even packaging up ChatGPT fitness plans and selling them.  Its appeal is obvious. ChatGPT answers questions in seconds, saving the need to sift through tons of information. You can ask follow-up questions, too, to get a more detailed and personalized answer. Its chatty tone is ideal for dispensing fitness advice, and the information is presented clearly. OpenAI is tight-lipped about the details, but we know ChatGPT was trained on data drawn from crawling websites, Wikipedia entries, and archived books so it can seem to be pretty good at answering general questions (although there’s no guarantee that those answers are correct.) So, is ChatGPT the future of how we work out? Or is it just a confident bullshitter? To test GPT’s ability to create fitness regimes, I asked it to write me a 16-week marathon training plan. But it was soon clear that this wasn’t going to work. If you want to train for a marathon properly, you need to gradually increase the distances you run each week. The received wisdom is that your longest run needs to be around the 20-mile mark. ChatGPT suggested a maximum of 10 miles. I shudder to imagine how I’d cope if I ran a marathon that underprepared. I’d be in a whole world of pain—and at serious risk of injuring myself.  When I asked it the same prompt again in a separate conversation—“Write me a 16-week marathon training plan”—it suggested running 19 miles the day before the race. Again, this would be a recipe for disaster. It would have left me exhausted on the marathon start line, and again, probably with an injury. I wasn’t sure why ChatGPT gave me two different answers to the same question, so I asked OpenAI. A spokesperson told me that large language models tend to generate a different answer to a question every time it’s posed, adding, “This is because it is not a database. It is generating a new response with each question or query.” Open AI’s website also explains that while ChatGPT can learn from the back-and-forth within a conversation, it’s unable to use past conversations to inform future responses.  When I asked OpenAI why ChatGPT had given me potentially harmful advice, the spokesperson told me: “It’s important to remind readers that ChatGPT is a research preview— and we let people know up front that it may occasionally generate incorrect information and may also occasionally produce harmful instructions or biased content.” One of my AI-generated plans wisely offers the caveat that it’s a good idea to check it with a coach. Another tells me to listen to my body and take rest days. Another doesn’t contain any warnings at all. The chatbot’s answers are inconsistent, and not terribly helpful.  Ultimately, I was left disappointed—and slightly concerned. It wasn’t going to work for me. However, as I scrolled through TikTok, Reddit, and Twitter, I discovered that plenty of other people have used ChatGPT to create workout plans. And some, unlike me, actually followed its suggestions. ChatGPT’s workout tips can be at least superficially impressive. Fellow fitness fanatic Austin Goodwin, based in Tennessee, came across it through his day job as a content marketer and quickly started playing around asking it general exercise-related questions. He asked it to explain what progressive overload in weightlifting was (gradually upping the weight you lift or the number of repetitions), and why a calorie deficit is needed for weight loss. “It was providing me with answers that I would expect a person of multiple years of knowledge to have,” he says. “It’s kind of like putting a Google or Wikipedia search on steroids—it amplifies that and takes it to the next level.” Goodwin isn’t the only person to see ChatGPT’s potential as a rival to Google search—Google’s management has reportedly declared it a “code red” threat.  I found out how good ChatGPT is at presenting information firsthand when I asked it to write a weightlifting plan (purely for theoretical purposes—I had no intention of pumping any AI-recommended iron.) It came back with a passable routine of exercises like squats, pull-ups, and lunges. To test its limits further, I told it my purpose was “to get lean” (again, I lied, for the noble purposes of journalism). It gave me an impressively caveated answer, with the advice that “for the purpose of getting lean, it's important to pay attention to your diet.” So far, so accurate.  Goodwin has been testing ChatGPT’s limitations by asking questions he already knows the answers to. So has Alex Cohen, another fitness hobbyist, who works for a health-care startup called Carbon Health. Cohen started by asking it to calculate his total daily energy expenditure (the total number of calories someone burns in a day, a useful tool for estimating how much you should consume in order to lose, maintain, or gain weight). He then asked it to create sample meal and workout plans. Like Goodwin, he was impressed by how it presented information. However, it quickly became clear that it’s no replacement for a nutritionist or a personal trainer.  “It’s not personalizing workouts based on my specific body shape or build, or my experience,” he says. And ChatGPT doesn’t ask users additional questions that could improve its answers.  Despite the variable quality of ChatGPT’s fitness tips, some people have actually been following its advice in the gym.  John Yu, a TikTok content creator based in the US, filmed himself following a six-day full-body training program courtesy of ChatGPT. He instructed it to give him a sample workout plan each day, tailored to which bit of his body he wanted to work (his arms, legs, etc), and then did the workout it gave him.  The exercises it came up with were perfectly fine, and easy enough to follow. However, Yu  found that the moves lacked variety. “Strictly following what ChatGPT gives me is something I’m not really interested in,” he says.  Lee Lem, a bodybuilding content creator based in Australia, had a similar experience. He asked ChatGPT to create an “optimal leg day” program. It suggested the right sorts of exercises—squats, lunges, deadlifts, and so on—but the rest times between them were far too brief. “It’s hard!” Lem says, laughing. “It’s very unrealistic to only rest 30 seconds between squat sets.” Lem hit on the core problem with ChatGPT’s suggestions: they fail to consider human bodies. As both he and Yu found out, repetitive movements quickly leave us bored or tired. Human coaches know to mix their suggestions up. ChatGPT has to be explicitly told. For some, though, the appeal of an AI-produced workout is still irresistible—and something they’re even willing to pay for. Ahmed Mire, a software engineer based in London, is selling ChatGPT-produced plans for $15 each. People give him their workout goals and specifications, and he runs them through ChatGPT. He says he’s already signed up customers since launching the service last month and is considering adding the option to create diet plans too. ChatGPT is free, but he says people pay for the convenience.  What united everyone I spoke to was their decision to treat ChatGPT’s training suggestions as entertaining experiments rather than serious athletic guidance. They all had a good enough understanding of fitness, and what does and doesn’t work for their bodies, to be able to spot the model’s weaknesses. They all knew they needed to treat its answers skeptically. People who are newer to working out might  be more inclined to take them at face value. This doesn’t mean AI models can’t or shouldn't play a role in developing fitness plans. But it does underline that they can’t necessarily be trusted. ChatGPT will improve and could learn to ask its own questions. For example, it might ask users if there are any exercises they hate, or inquire about any niggling injuries. But essentially, it can’t come up with original suggestions, and it has no fundamental understanding of the concepts it is regurgitating Given that it’s trained on the web, what it comes up with may be something you didn’t know, but plenty of others will, points out Philippe De Wilde, a professor of artificial intelligence at the University of Kent, England. And while many of its answers are technically correct, a human expert will almost always be better.  If it’s useful at all, ChatGPT might be best treated as a fun way of spicing up a workout regime that’s started to feel a bit stale, or as a time-saving method of proposing exercises you may not have thought of yourself. “It’s a tool, but it’s not gospel,” says Rebecca Robinson, a consultant physician in sports and exercise medicine in the UK. Away from the internet, I ended up following advice from books and magazines written by running experts to draw up my own marathon training plan, which is serving me pretty well four weeks in.  I’m not alone in mostly discarding ChatGPT’s advice—Lem only followed its suggestions for the purposes of filming one video, while Yu has also switched back to his old AI-free workout routine, which he enjoys a lot more, he says. “I’d rather just continue doing that and modifying it, rather than trying to give ChatGPT more info and still not ending up being super excited.”  Kenyan runners, like many others, are grappling with the impact of expensive, high-performance shoes. AI-powered NPCs that don’t need a script could make games—and other worlds—deeply immersive. It was able to draw on vast amounts of data to refine its playing style and adjust its tactics as matches progressed. Something peculiar and slightly unexpected has happened: people have started forming relationships with AI systems. Discover special offers, top stories,
            upcoming events, and more. Thank you for submitting your email! It looks like something went wrong. 
                We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.  © 2024 MIT Technology Review