Sponsored Multi-die system or chiplet-based technology is a big bet on high-performance chip design—and a complex challenge. In partnership withSynopsys To say that semiconductor technology is part of the fabric of modern society is not an overstatement—it underpins everything from our cars to our phones to our home appliances.  In 2021, the semiconductor industry shipped a record 1.15 trillion chips, and sales topped half a trillion dollars worldwide, while thousands of new chip designs entered the market.  A new semiconductor chip architecture, termed “multi-die system” or “chiplet-based design,” will be instrumental in meeting this decade’s burgeoning demand for processing power. Because this new approach will pose technical challenges throughout the semiconductor ecosystem—remaking how products are imagined, designed, and fabricated—opportunities for innovators across the value chain will emerge from this shift. Business leaders across industries who identify use cases for these advanced chips will benefit from their ability to power unique and customized customer experiences. Few business leaders, however, are keeping pace with the latest developments in this arena. Multi-die technology is still an enigma to many executives. A recent poll by MIT Technology Review Insights asked business leaders about their awareness of this design strategy—and found that 62% of respondents are either uninterested, unaware, or only somewhat aware of this technology’s capabilities. A few chip-reliant industries obviously need to keep a close eye on advancements in semiconductor tech: automotive companies, artificial intelligence firms, hyperscale data processing organizations, and smart device manufacturers, to name a few. But because advanced semiconductors are foundational to modern-day business operations, even executives whose functions don’t directly touch technology should care about chip design trends—including those that will define the sector’s next chapter.  While the global semiconductor shortage that began in 2020 had its proximate causes in natural disasters and geopolitics, its effects drew widespread attention to the fact that just about every industry relies on chips. And pandemic-related ripple effects aside, the silicon status quo has been in flux for some time. New technologies like artificial intelligence and machine learning (AI/ML), which require greater computing efficiency and performance, have strained traditional systems in recent years.  With the rise of the Internet of Things (IoT), customers have also come to expect intelligence in everything from refrigerators to lightbulbs. Innovators are responding accordingly. Our poll found that nearly one-third (31%) of business executives plan to improve upon their companies’ existing smart products, and almost another third (29%) intend to add AI/ML capabilities to their products soon. Only 9% of respondents said they were not producing IoT or connected devices. This type of technology, however, necessitates robust edge computing and on-device processing, which requires greater and more efficient hardware performance. Complicating matters, the cloud data centers powering this compute shift are also voracious energy consumers. This is another area where traditional silicon is stagnating: sustainability. The cost of producing superfluous silicon is not just bad for business—it has an environmental impact. And while there’s an ongoing push toward net-zero carbon emissions within the semiconductor supply chain, the industry isn’t yet on track to meet the emissions standards set forth in the UN 2016 Paris Agreement. An industry shift toward multi-die design could be part of the solution to these challenges. Instead of a single monolithic chip (“system on chip”), multi-die designs consist of a collection of chips (chiplets or dies) linked in a sophisticated package (“systems of chips”), which can include stacking blocks in a 3D configuration for greater density. Multi-die system designs are capable of supporting the rollout of AI/ML at scale, and they can improve silicon yields, reducing waste during chip manufacturing. When it comes to the business use cases for multi-die systems, Patrick Moorhead, founder, CEO, and chief analyst at global technology consulting firm Moor Insights & Strategy, notes that these custom designs may soon be a key differentiator for companies looking to stand out among competitors. “As more people are looking at more custom silicon as a way to differentiate what they bring to the table, that’s what businesspeople should be looking at,” he says. “Chiplets enable smaller companies with smaller pocketbooks to use semiconductors for unique competitive advantage.”  Gerry Talbot, a corporate fellow at semiconductor company AMD, boils the business value of chiplets down to the wide range of use cases for the technology. “I don’t think [business leaders] will be so excited about the technology itself,” he says, “as much as the application and the enablement of a unique user experience that can help sell their product.” Download the report. This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.  Kenyan runners, like many others, are grappling with the impact of expensive, high-performance shoes. AI-powered NPCs that don’t need a script could make games—and other worlds—deeply immersive. It was able to draw on vast amounts of data to refine its playing style and adjust its tactics as matches progressed. Something peculiar and slightly unexpected has happened: people have started forming relationships with AI systems. Discover special offers, top stories,
            upcoming events, and more. Thank you for submitting your email! It looks like something went wrong. 
                We’re having trouble saving your preferences.
                Try refreshing this page and updating them one
                more time. If you continue to get this message,
                reach out to us at
                customer-service@technologyreview.com with a list of newsletters you’d like to receive.  © 2024 MIT Technology Review