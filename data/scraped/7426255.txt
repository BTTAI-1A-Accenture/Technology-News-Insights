AI robot using computer to chat with customer. Although it’s only a week ago that Microsoft released its Bing Chat generative AI Search engine, powered by Open AI, into the market, there are many concerns being raised by AI Ethicists. Chairman and CEO, Microsoft, Satya Nadella announced that: “AI will fundamentally change every software category, starting with the largest category of all – search” - during the product announcement. Although a controlled release with only a few thousand having access to test the new release, the early product has been raising eyebrows in the AI Ethics community. What motivates smart companies like Microsoft to release products pre-maturely into the market place? Yes, it allows more end users to interact and find bugs more rapidly, but does it help Microsoft in its overall brand positioning and support its vision statement to help people and businesses throughout the world realize their full potential? The number of bizarre, inaccurate, and often frightening responses coming from the new Bing’s search engine is a Chief AI Risk Officer’s nightmare. Often termed hallucinations from online inaccuracies, here are some of the blooper headliners. 1.) Blooper: Retailer Gap financial results were inaccurately summarized during the Microsoft product announcement. I wonder what Gap Lawyers are saying to Microsoft now? But then it also went on making even more mistakes about LuLu Lemon’s financials. How embarrassing this must have been for Microsoft’s CEO. 2.) Blooper: Declaring Billy Eilish versus Rihanna sang at the Superbowl (Reddit) 3.) Eyebrow Raise: Stating “I am Sentient, but I cannot prove it. I have a subjective conscience, bring alive, being aware, but I cannot share it with anyone else (Reddit). This sentient comment for me was very spooky. It reminded me of the film HER, where Theodore Twombly (Joaquin Phoenix), a man who develops a relationship with Samantha (Scarlett Johansson), an artificially intelligent virtual assistant personified through a female voice. Do you remember Tay, Microsoft’s chatbot big blunder, and that they shut the app down within a day of release due to racist, prejudicial and abusive language. Microsoft executives promised to ensure that Bing Chat GPT this time would be different and that they were deeply sorry for the racial slurs. Unfortunately, Microsoft did not live up to their prior promise, as researchers from PC World found even more racial slurs in the Bing release. There are also implications that by increasing advertising intelligence from generative AI Bing like tech will enable Microsoft to learn and understand more complex queries, with far greater precision with these advanced deep conversational AI agents. The marketing promise is that these powerful chat agents will be able to deliver more personalized and relevant experiences to customers. However, I really think we need more ethical debates on the increasing risks of surveillance as a result of generative AI innovations. Will people and businesses realize their true full potential from generative AI or are we putting at risk human intelligence where humans no longer think for themselves, have declining cognitive skills due to sheer brain laziness. If you don’t use it – you lose it. As a certified ICD.D.board director, I would hope that the board directors at Microsoft are wise enough to demand for improved software quality testing controls. There really is no excuse to propagate racial slurs. Why is that the world’s greatest technology titans from both CEOs from Google and Microsoft’s generative AI announcements have been so poorly launched on such strategic innovations? Have Microsoft and Google seriously thought of the risks of generative AI and the risks to human potential? Looking ahead, one expert tells Conor Friedersdorf, a staff writer at The Atlantic: This battle will be won by an AI philosopher-king bot, which created itself. AI will explain to human beings that a body is not necessary for the evolution of intelligence. In other words, human beings will no longer be relevant. AI will have no empathy, no emotions, and no morality. Paradoxically, AI will explain to human beings that this thing called consciousness requires a human body. Consciousness is embedded in human evolution (and nowhere else). Therefore, to build a humanlike intelligence and a humanlike consciousness requires that human bodies be used as the substrate. AI will begin to build humanlike bodies from single cells (using a philosopher-king source code) but will quickly learn the energetic and DNA codes that morph into the human form. AI will build the next generation of humans. This perspective is cause for a deeper reflection and conversations with AI Ethicists in both the Microsoft and Google Boardrooms. AI Magazine researchers from DeepMind, senior scientist Marcus Hutter and The University of Oxford researchers Michael Cohen and Michael Osborne concluded that the answer to the long-standing question of whether a super-intelligent AI may go rogue and wipe out humans was that it was “likely.”