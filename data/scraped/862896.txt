Share At the recent Google Cloud Next event in San Francisco, Google surprised everyone by announcing that they‚Äôre offering Llama 2 and Code Llama from Meta, as well as Falcon LLM on Google Cloud‚Äôs Vertex AI. This was unexpected because Google was the only cloud service provider that hadn‚Äôt partnered with rival institutions to host Llama 2 or any other open source LLM models before this.¬† It appears this decision by Google has been taken keeping enterprises in mind who are staple customers of Vertex AI but are looking for more options. If we go by the trend, after GPT-4, Llama 2 is the most sought after large language model, considering it is open-sourced and commercially available. In the case of Llama 2, Google said that it is the only cloud provider offering both adapter tuning and RLHF. Despite being ad rivals, Meta and Google have put aside their competition when it comes to large language models. Meta directly does not want to compete with anyone in the LLM business and is happy to provide Llama 2 to everyone. Now with Google Cloud having Llama 2, Meta has conquered every territory possible. In fact, didn‚Äôt Meta just reverse the saying: ‚ÄúIf you are good at something, never do it for free‚Äù? However, Google accepting Llama 2 raises one question: Is PaLM 2 not capable enough? Google Bard currently uses PaLM 2 and it seems like it isn‚Äôt a favourite among enterprises as they cannot customise it according to their requirements, in addition to its poor responses when compared to ChatGPT.¬† The tech giant claims that its Model Garden has a collection of 100+ models including enterprise-ready foundation model APIs, open source models, and task-specific models from Google and third parties. Google should understand that when it comes to LLMs, it‚Äôs not about the quantity but about the quality.¬† Recently OpenAI also took cues from Meta‚Äôs approach and is now working to provide customisation options for GPT-4 and GPT-3.5 while avoiding open sourcing. To achieve this, the creator of ChatGPT recently introduced the GPT-3.5 Turbo API for fine-tuning. Additionally, it has partnered with Scale to fine-tune GPT-3.5,¬†in order to woo enterprises. Google might have been late to the game, but there is still hope, following the AWS route. Google has understood the importance of hosting multiple LLMs, much like Amazon‚Äôs Bedrock platform. Currently, Bedrock hosts models from AI21, Cohere, Anthropic Claude 2, and Stability AI SDXL 1.0. At present, Microsoft is actively exploring different LLMs. Microsoft Azure currently encompasses all OpenAI services via APIs, including the Azure OpenAI Service. This empowers enterprises and developers to create applications using GPT, DALL¬∑E, and Codex. When Llama 2 was launched by Meta, Azure was announced as the preferred partner for Llama 2. It seems like Microsoft is not going to stop here, as it further plans to sell a new version of Databricks‚Äô software on Azure that will help customers make AI apps for their businesses. This new service will help companies make AI models from scratch or repurpose open-source models as an alternative to licensing OpenAI‚Äôs proprietary ones.¬† In the latest quarter, Azure emerged as the winner with 26% revenue growth, thanks to Azure OpenAI services. However, now with Llama 2 being the common factor among all three clouds, it will be intriguing to witness who will lead the LLM cloud game in the upcoming quarter. What about Gemini? As Vertex AI now hosts Llama 2 and has shifted its focus to smaller models, similar to the approaches of Microsoft and AWS, it raises the question of the feasibility of creating Gemini to take on GPT-5. This consideration is particularly relevant as OpenAI has also redirected its focus towards serving enterprises.¬† Not to forget, Google‚Äôs Codey has a new rival called Code Llama, only time will tell who codes better, alongside its adoption among the enterprise customers and developers. üì£ Want to advertise in AIM? Book here By mid-2023, Ragas gained significant traction, even catching the attention of OpenAI, which featured their product during a DevDay event. Discover how Cypher 2024 expands to the USA, bridging AI innovation gaps and tackling the challenges of enterprise AI adoption Email:info@aimmediahouse.com Our Offices AIM India#280, 2nd floor, 5th Main, 15 A cross, Sector 6, HSR layout Bengaluru, Karnataka 560102 AIM Americas99 South Almaden Blvd. Suite 600 San Jose California 95113 USA ¬© Analytics India Magazine Pvt Ltd & AIM Media House LLC 2024