AI-generated tracks simulating artists like Drake and The Weeknd have spread across social media in recent weeks, forcing record labels, publishers, and streaming platforms to reckon with its potential business impact on musicians. Some artists like Grimes are embracing the technology by setting up AI content-creation tools in an attempt to profit from the use of their voices. Others, such as Ice Cube, are rejecting the technology outright. Regardless of artists' views, adoption of the technology is on the rise. Entertainment lawyers are planning strategies for how they can protect their clients, including using existing tech designed to detect and enforce copyright protections under the Digital Millennium Copyright Act, or DMCA, and invoking right of publicity laws. "Music is unfortunately a canary in a coal mine sometimes with new technology," said Jordan Bromley, entertainment group leader at Manatt, Phelps, & Phillips, LLP, speaking on a May 9 panel hosted by the firm. Manatt's panel included Bromley; his colleagues Nathaniel Bach and Sarah Moses; Mitch Glazier, chairman and CEO of the Recording Industry Association of America; and Jeffrey Bennett, the general counsel for the Hollywood actors and music artists union SAG-AFTRA. Here are four main takeaways on the legal and business challenges of AI in music called out by the panelists: Technology exists today to identify copyright violations in songs after they are released. The Verge reported that Universal Music Group used DMCA detection tools to submit a takedown request for an AI-generated track imitating Drake and The Weeknd that included a traceable tag from the producer Metro Boomin, for example. But the precise manner that AI-generated music, trained on a human artist's body of work, could violate copyright laws is still being defined. "We don't always have information about how a particular AI song is created and how the software works," Manatt's Bach said. "Figuring out where the rubber meets the road there in terms of the internal working processes, what was done by the AI, what was done with the human, and for what purpose, is going to be really central." 
                                Related stories
                               The copyright rules surrounding AI training models are currently being litigated in other parts of the art world. The company Getty Images and several visual artists have separately sued AI image generators like Stable Diffusion, Midjourney, and Stability AI around alleged use of their works in training programs. During Manatt's panel, RIAA's Mitch Glazier raised the idea that an AI model trained on existing songs should legally be defined as a mechanical reproduction, which would require a license. Right of publicity laws, which protect an individual's right to control the commercial use of their personal characteristics, could be a useful tool for lawyers looking to protect artists from AI-generated imitations. If a song that includes an AI-generated voice that mimics a well-known artist is making money, it may violate right of publicity laws in certain states. "You have to look at what is the intent and commercial benefit to the person who is putting it out, and then what is the commercial consequence to the market itself and to the artist on the other works that they have out in the marketplace," RIAA's Glazier said. Because right of publicity laws are written at the state level, they can be more time consuming to enforce and aren't a perfect solution, the attorneys said. "It's sort of a patchwork of state laws," SAG-AFTRA's Bennett said. "It's time to take it out and see what we can do with it." The sheer volume of AI songs spit out onto streaming platforms could create detection challenges for rights holders. Music platforms like Spotify and YouTube could set limits on how much AI music spreads, the attorneys said.  "Even if we get the tools, we need to think about enforcement very carefully, because this is a whole new game of whack-a-mole," Manatt's Bromley said. Separately, the business incentives between the platforms and rights holders may not be aligned. Some streaming apps may push to add AI-generated tracks to their libraries as a way to cut costs by reducing the royalty payments due to human artists, record labels, and publishers. "If you're a [digital streaming platform] and you want to add to your bottom line, you create AI technology that can make functional music and you throw all that on your playlists and you shift 10% of total content costs to your bottom line," Bromley said. "If a company wants to work with the music business and be on the right side of history, they won't do that." Record labels are already looking for ways to regulate how streaming platforms work with AI tools. Universal Music Group sent letters in March to Spotify and Apple Music requesting that they block artificial-intelligence companies from using their catalogs to train AI models, Billboard reported. While much of the conversation in Manatt's panel centered on the risks that AI presents to the music industry, there were a few notes of optimism about how the technology could benefit musicians. "The other side of this coin is this is a great creative tool if embraced properly and used appropriately and responsibly," Bromley said.  AI-generated works that share earnings with an artist, such as Grimes' Elf.tech tool, could end up creating a new revenue line for performers. Universal Music Group announced on Tuesday a partnership with AI-music startup Endel to help its artists and labels create "soundscapes for daily activities like sleep, relaxation, and focus by harnessing the power of AI." "If you look at history, those who have decided to become partners and work with the music community have thrived with the music community," RIAA's Glazier said. "Those who have decided that they're going to use legal loopholes and try to pay less, or pay nothing, you don't really hear about them much today." 
                                Read next
                               Jump to