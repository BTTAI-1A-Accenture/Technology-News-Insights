
UPDATED 14:14 EDT / MAY 27 2023

 
BREAKING ANALYSIS					        	                        by 
Dave Vellante

 The era of AI everything continues to excite. But unlike the internet era, where any company announcing a dot-com anything immediately rose in value, the AI gods appear to be more selective. Nvidia Corp. this week beat its top-line whisper number by more than $300 million and the company’s value is rapidly approaching $1 trillion. Marvell Technology Inc. narrowly beat expectations this week but cited future bandwidth demand driven by artificial intelligence and the stock was up more than 20% on Friday. Broadcom Inc. was up nearly 10% on sympathy with the realization that connect-centricity beyond the central processing unit is what the company does really well. Meanwhile, other players such as Snowflake Inc., which also narrowly beat earnings Wednesday and touted AI as a future tailwind, got hammered as customers dial down cloud consumption. In this Breaking Analysis, we look at the infrastructure of AI examining the action at the silicon layer specifically around Nvidia’s momentum. Since much of AI is about data, we’ll also look at the spending data on two top data platforms, Snowflake and Databricks Inc., to see what the survey data says and examine the future of real-time data and automation as a catalyst for massive productivity growth in the economy. To do so, we have a special Breaking Analysis panel with John Furrier and David Floyer. Two years ago we published this research report, laying out our thesis as to how Nvidia will disrupt the $1 trillion x86 installed base.  Basically it was a roadmap of Nvidia’s plan to take a massive chunk out of Intel Corp.’s general-purpose data center dominance. We had a positive outlook on the Nvidia’s prospects specifically thanks to its software expertise and end-to-end capabilities. We noted not just the GPUs, but the tens of thousands of other components, the networking, the intelligent network interface cards and the full stack that Nvidia was building. Here’s an excerpt from that report: Nvidia wants to completely transform enterprise computing by making datacenters run 10X faster at 1/10th the cost. Nvidia’s CEO, Jensen Huang, is crafting a strategy to re-architect today’s on-prem data centers, public clouds and edge computing installations with a vision that leverages the company’s strong position in AI architectures. The keys to this end-to-end strategy include a clarity of vision, massive chip design skills, new Arm-based architectures that integrate memory, processors, I/O and networking; and a compelling software consumption model. Nvidia’s recent results are evidence that vision appears to be coming to fruition.  John Furrier called ChatGPT the “Web browser moment.” Jensen Huang calls it the iPhone moment. Either way, Nvidia blew away its numbers with a $670 million revenue beat and cited its second-half supply is going to be significantly better… and laid out a forceful and compelling narrative that budgets are shifting away from x86 to what the company calls accelerated computing. Nvidia’s valuation is nearly nine times that of Intel’s, and ChatGPT has been a massive catalyst for Nvidia. Here’s a summary of the conversation that followed on our panel. In the conversation, Floyer and Furrier talked about major shifts occurring in the tech industry landscape. AI infrastructure, semiconductors and data are the crux of these transformations, driven significantly by the adoption of parallel computing and cloud-optimized GPUs. The following three key points emerged: In addition, there’s more than parallel computing at play. Other facets of the semiconductor industry are also undergoing significant changes: Bottom Line: The combination of AI infrastructure, semiconductors, and data will drive the next wave of technological advancements. Companies that can successfully ride this wave will likely shape the future of the industry. The battle among industry players is set to intensify, making this a crucial space to track. Watch three top analysts discuss the future of AI and the shift to the AI-powered data center. In a candid conversation with a community member of theCUBE’s, this deep AI expert shared the following:  So with that as a backdrop, let’s look at some of the silicon competition to Nvidia and other firms possibly getting a boost from AI. Nvidia is disrupting Intel, that’s clear, as is Arm Ltd. Advanced Micro Devices Inc. is competing head on with both companies and has done an amazing job of bring AMD back to prominence. All the cloud players are developing silicon, as is IBM Corp. Broadcom is competing for share in merchant silicon and is focused on the surrounding components including intelligent NICs, along with Marvell in connectivity. And several other players are building semiconductor capabilities, including Apple, Tesla and Meta Platforms Inc. And finally Chinese companies are designing and manufacturing silicon chips in an effort to achieve independence. So Nvidia is far from alone in this market, but it has a big lead.  Here’s a summary of the analyst conversation on Nvidia’s success in the AI space, the importance of neural networks, the role of hyperscalers and geopolitical concerns. First, the panel discussed Nvidia’s lead in the AI business, primarily thanks to its GPU technology and innovative CUDA software. They believe Nvidia will continue to innovate by adding more neural networks to its repertoire. Both Apple and Tesla were noted for their heavy investments in neural networks, with the former dominating consumer computing and the latter focusing on inference work for its autonomous vehicles. The conversation led to the broader picture of AI, which they see as a driving force toward automation. Next, the hyperscalers were brought into the mix, with Amazon Web Services Inc., Google LLC, Microsoft Corp., and Alibaba Group Holding Ltd. all developing their own AI products and chips. China’s looming influence in this market is also noted. Amazon, with its deep experience in silicon and a long history with AI, was highlighted as a potential leader. AWS’ approach to generative AI and aggressive messaging were seen as pivotal to its positioning. Third, the conversation turned to the example of AWS’ acquisition of Annapurna Labs. AWS wasn’t satisfied with Intel’s performance or price, so it began partnering with Annapurna, and ultimately bought the company. AWS then used Annapurna to design Arm-based chips in-house. The panel speculated if AWS could follow a similar path to compete with Nvidia, potentially by acquiring AI startups to innovate its offerings. But Amazon.com CEO Andy Jassy’s famous quote that “there’s no compression algorithm for experience” favors Nvidia. The following key points are noteworthy: Watch this 10-minute deep dive into the competitive landscape for silicon chip design, the role of hyperscalers, AI inferencing and the cost of AI.  Bottom line: Nvidia has plenty of competition but their lead is substantial and in the world of semiconductors major shifts go in long cycles.  Let’s shift gears and look at Snowflake’s quarter and talk about where it fits in AI. The reason we say Snowflake catches a cold is because it narrowly beat but was very cautious about the outlook, citing more tepid consumption patterns relative to the past — and investors sold. Ironically, Snowflake’s chief financial officer was suffering from a nagging cough that plagued him throughout the conference call. Despite the selloff, Snowflake’s momentum is still strong with very low churn. The fact. however. is that customers are optimizing costs by reducing retention policies – which lowers storage costs and makes queries run faster – so less storage and compute equals lower revenue.  Snowflake’s play is to be the iPhone of data apps. Or the App Store if you will. It wants to be the best platform to build data apps — better than the hyperscalers, better than Databricks… better than anyone. And it has made some acquisitions such as Applica and now Neeva Inc., which support the envisioned outcomes of Snowpark, a developer experience announced in 2020 that use interfaces other than SQL (such as Python, Scala and others). The following summarizes the discussion on the future of data infrastructure in relation to AI and automation, using Snowflake and Databricks as case studies. Floyer is of the opinion that future company architectures should aim to reduce their workforces through automation. To do so, transactional data and analytic data need to be unified, and they have to share the same databases to minimize time lags and drive real-time automation. He believes that in the long run, architectures such as Snowflake may not support this model as they would require a more direct approach from data sources to applications. Regarding Databricks, Furrier discussed how it has successfully capitalized on the big-data wave. However, John also believes that the introduction of AI will change this landscape, bringing about a shift in the infrastructure platforms. He feels databases will become invisible, automated by AI, and data storage will be controlled by developers and applications, leading to a complete reversal of the current script. Floyer responded by expressing the importance of databases for maintaining consistency in the future, even in a more distributed form. He doesn’t believe developers will completely take over the role of data management, as databases relieve developers of many tasks. He also believes that developers will benefit from a plethora of new tools, leading to simpler orchestration of automation. Bottom Line: There will be a major shift in the data infrastructure landscape toward distributed, developer-controlled databases and increased automation. However, there is a divergence in opinion on how much control developers will have over data management and the extent to which databases will remain an essential tool. The underlying theme is that change is inevitable, and companies will need to adapt to stay relevant. Watch this clip of the three analysts discussing Snowflake, Databricks, developers and the future of data platforms. The chart below is based on a survey of 1,700 information technology decision makers or ITDMs comprising 264 Snowflake accounts. It shows the granularity of Snowflake’s Net Score across those 264 accounts. Net Score is a measure of spending velocity based on Enterprise Technology Research’s proprietary methodology. The lime green bars show the percentage of new customers adding Snowflake. The forest green is the percentage that are spending 6% or more. The gray signifies flat spend. The pinkish bars show spending down 6% or more and the bright red is churn. Subtract the reds from the greens and that equals Net Score. The blue line shows Net Score and the yellow line shows the share of mentions within the data set.  The notable points are: Let’s now share a different view and bring Databricks into the equation and see how they stack up with Snowflake. This chart compares the data from Snowflake (N=264), Databricks (N=225) and Streamlit (N=111). It plots Net Score or spending momentum on the Y axis and account overlap/presence based on the Ns on the X axis. The squiggly lines indicate the progression over time.  Several points are notable in the data: Let’s delve into the key points that arose during this conversation about these data points. The discussion begins with an acknowledgment from Furrier of the validity of Snowflake’s churn data. Its churn rates are low despite the current economic headwinds causing a market slowdown. So they’re not losing customers, similar to the dynamic among the cloud players. Major shifts, such as the hype around AI right now, tend to cause a freeze in the buyer market. This leads to a “wait and see” approach, further slowing down spending in the sector. But customers are not defecting. An important comparison arises between Snowflake and Databricks, two significant players in the market. Snowflake’s strong business model has set it apart and allowed it to lead the market in the early stages. However, Databricks has gained substantial traction through leveraging the open-source community and consistently enhancing its robust product offerings. A salient point in the discussion revolves around data retention policies. Snowflake, for example, stores an extensive amount of data for its clients, but the question arises: Is all this stored data being utilized effectively? This was a topic of conversation on the earnings call where customers are being forced to control costs and shortening retention times is a logical way to do so. Floyer stressed that the value of data diminishes as it ages, prompting a shift toward efficiently capturing and extracting the value of data close to its source before disposing of it. Barclays analyst Raimo Lenschow asked what we thought was a salient question on the earnings call: Is the trend of shorter retention times potentially enduring and will this lead to a change in the future growth of data storage needs Furrier introduced the concept of “hyper data scalers.” These could be entities similar to cloud hyperscalers but focused on storing vast amounts of data for foundational AI models. The conversation concludes with a focus on the value of historical data for AI, particularly for pattern recognition and training AI models. There’s speculation about a new model of data infrastructure where the emphasis is less on storage and more on real-time use and domain-specific data. This could significantly alter the landscape of data handling in the future. Bottom Line: The current traction of both Snowflake and Databricks is notable. Both companies have strong managements and seemingly loyal customer bases and they’ll both likely leverage AI effectively. The market is large enough for both to thrive in the near to mid-term with longer-term trends around real-time data and AI inferencing challenging the status quo.  Listen and watch the three analysts discuss churn rates, real-time data, whether more data will become ephemeral and if that will negatively impact storage growth. The world of applications is shifting toward data apps. Today’s data silos are largely a function of data being embedded in applications that automate processes. Increasingly, we believe business logic will be infused into data and apps will be build using this new model. The example we often use is Uber for the enterprise, where a digital twin of your businesses is created. People, places and things are digitized as independent data elements, but those data “products” are discoverable, governed and have coherence. A semantic layer enables these data elements to be completely connected and understood by the system and each other. Using the Uber example: Riders and drivers are connected with data related to destinations, estimated times of arrival, and prices, based on demand and supply. This is done in real time without incurring significant tradeoffs among availability, latency and consistency. We believe that these types of apps will require new thinking around data architectures, standards and platforms. But more important, they will drive new levels of automation and productivity for businesses. Here’s a bulleted summary of the closing conversation between the three analysts using the Uber example and the impact on productivity: Unlike previous generations of companies, particularly witnessed in demise of the East Coast minicomputer business (Apollo, DEC, DG, Prime, Wang), today’s leaders are much more paranoid about disruptive technologies. But blind spots exist and often incumbents are so focused on protecting their franchises that it leads to slower growth and lack of innovation. AI represents an opportunity for both incumbents to drive automation into existing platforms and disruptors to bring new models to industries. Unlike the web, which was often seen as a bifurcated opportunity between bit- and atom-based businesses, AI has the potential to be even more ubiquitous. Watch the three analysts discuss the Uber example, the impact automation has had on Uber’s revenue per employee, and the future imperative of leveraging real time data. Many thanks to Alex Myerson and Ken Shifman on production, podcasts and media workflows for Breaking Analysis. Special thanks to Kristen Martin and Cheryl Knight, who help us keep our community informed and get the word out, and to Rob Hof, our editor in chief at SiliconANGLE. Remember we publish each week on Wikibon and SiliconANGLE. These episodes are all available as podcasts wherever you listen. Email david.vellante@siliconangle.com, DM @dvellante on Twitter and comment on our LinkedIn posts. Also, check out this ETR Tutorial we created, which explains the spending methodology in more detail. Note: ETR is a separate company from Wikibon and SiliconANGLE. If you would like to cite or republish any of the company’s data, or inquire about its services, please contact ETR at legal@etr.ai. Here’s the full video analysis:  All statements made regarding companies or securities are strictly beliefs, points of view and opinions held by SiliconANGLE Media, Enterprise Technology Research, other guests on theCUBE and guest writers. Such statements are not recommendations by these individuals to buy, sell or hold any security. The content presented does not constitute investment advice and should not be used as the basis for any investment decision. You and only you are responsible for your investment decisions. Disclosure: Many of the companies cited in Breaking Analysis are sponsors of theCUBE and/or clients of Wikibon. None of these firms or other companies have any editorial control over or advanced viewing of what’s published in Breaking Analysis. THANK YOU Virtual networking startup ZeroTier raises $13.5M to juice product development A close look at JPMorgan's aggressive cloud migration Why Databricks vs. Snowflake is not a zero-sum game X’s new AI training opt-out setting draws regulatory scrutiny Cyber insurance provider Cowbell reels in $60M to grow its product portfolio New AI models flood the market even as AI takes fire from regulators, actors and researchers Virtual networking startup ZeroTier raises $13.5M to juice product development CLOUD - BY DUNCAN RILEY . 2 HOURS AGO A close look at JPMorgan's aggressive cloud migration CLOUD - BY PAUL GILLIN . 2 DAYS AGO Why Databricks vs. Snowflake is not a zero-sum game BIG DATA - BY GUEST AUTHOR . 2 DAYS AGO X’s new AI training opt-out setting draws regulatory scrutiny AI - BY MARIA DEUTSCHER . 3 DAYS AGO Cyber insurance provider Cowbell reels in $60M to grow its product portfolio SECURITY - BY MARIA DEUTSCHER . 3 DAYS AGO New AI models flood the market even as AI takes fire from regulators, actors and researchers AI - BY ROBERT HOF . 3 DAYS AGO Forgot Password? Like Free Content? Subscribe to follow.