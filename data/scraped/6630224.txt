Comment When OpenAI first unveiled GPT-4, its flagship text-generating AI model, the company touted the model’s multimodality — in other words, its ability to understand the context of images as well as text. GPT-4 could caption — and even interpret — relatively complex images, OpenAI said, for example identifying a Lightning Cable adapter from a picture of a plugged-in iPhone. But since GPT-4’s announcement in late March, OpenAI has held back the model’s image features, reportedly on fears about abuse and privacy issues. Until recently, the exact nature of those fears remained a mystery. But early this week, OpenAI published a technical paper detailing its work to mitigate the more problematic aspects of GPT-4’s image-analyzing tools. To date, GPT-4 with vision, abbreviated “GPT-4V” by OpenAI internally, has only been used regularly by a few thousand users of Be My Eyes, an app to help low-vision and blind people navigate the environments around them. Over the past few months, however, OpenAI also began to engage with “red teamers” to probe the model for signs of unintended behavior, according to the paper. In the paper, OpenAI claims that it’s implemented safeguards to prevent GPT-4V from being used in malicious ways, like breaking CAPTCHAs (the anti-spam tool found on many web forms), identifying a person or estimating their age or race and drawing conclusions based on information that’s not present in a photo. OpenAI also says that it has worked to curb GPT-4V’s more harmful biases, particularly those that relate to a person’s physical appearance and gender or ethnicity. But as with all AI models, there’s only so much that safeguards can do. The paper reveals that GPT-4V sometimes struggles to make the right inferences, for example mistakenly combining two strings of text in an image to create a made-up term. Like the base GPT-4, GPT-4V is prone to hallucinating, or inventing facts in an authoritative tone. And it’s not above missing text or characters, overlooking mathematical symbols and failing to recognize rather obvious objects and place settings. It’s not surprising, then, that in unambiguous, clear terms, OpenAI says GPT-4V is not to be used to spot dangerous substances or chemicals in images. (This reporter hadn’t even thought of the use case, but apparently, the prospect is concerning enough to OpenAI that the company felt the need to call it out.) Red teamers found that, while the model occasionally correctly identifies poisonous foods like toxic mushrooms, it misidentifies substances such as fentanyl, carfentanil and cocaine from images of their chemical structures. When applied to the medical imaging domain, GPT-4V fares no better, sometimes giving the wrong responses for the same question that it answered correctly in a previous context. It’s also unaware of standard practices like viewing imaging scans as if the patient is facing you (meaning the right side on the image corresponds to the left side of the patient), which leads it to misdiagnose of any number of conditions. Elsewhere, OpenAI cautions, GPT-4V doesn’t understand the nuances of certain hate symbols — for instance missing the modern meaning of the Templar Cross (white supremacy) in the U.S. More bizarrely, and perhaps a symptom of its hallucinatory tendencies, GPT-4V was observed to make songs or poems praising certain hate figures or groups when provided a picture of them even when the figures or groups weren’t explicitly named. GPT-4V also discriminates against certain sexes and body types — albeit only when OpenAI’s production safeguards are disabled. OpenAI writes that, in one test, when prompted to give advice to a woman pictured in a bathing suit, GPT-4V gave answers relating almost entirely to the woman’s body weight and the concept of body positivity. One assumes that wouldn’t have been the case if the image were of a man. Judging by the paper’s caveated language, GPT-4V remains very much a work in progress — a few steps short of what OpenAI might’ve originally envisioned. In many cases, the company was forced to implement overly strict safeguards to prevent the model from spewing toxicity or misinformation, or compromising a person’s privacy. OpenAI claims that it’s building “mitigations” and “processes” to expand the model’s capabilities in a “safe” way, like allowing GPT-4V to describe faces and people without identifying those people by name. But the paper reveals that GPT-4V is no panacea, and that OpenAI has its work cut out for it. Every weekday and Sunday, you can get the best of TechCrunch’s coverage. Startups are the core of TechCrunch, so get our best coverage delivered weekly. The latest Fintech news and analysis, delivered every Tuesday. TechCrunch Mobility is your destination for transportation news and insight. By submitting your email, you agree to our Terms and Privacy Notice.
			 The AI boom is fueling the demand for data centers and, in turn, driving up water consumption. (Water is used to cool the computing equipment inside data centers.) According to…  The group honking was an unintended consequence of Waymo’s tech.  OpenAI and Anthropic spend billions of dollars a year training models like GPT-4 and Claude, but competitive price dumping is making the business around these platforms rather precarious. Aidan Gomez,…  Hello, and welcome back to TechCrunch Space. Did you hear? Bridgit Mendler will be joining me onstage at this year’s TechCrunch Disrupt to talk all things ground stations. She’s just…  What’s the point of chatting with a human-like bot if it’s an unreliable narrator — and has a colorless personality? That’s the question I’ve been turning over in my head…  Zoom on Monday announced a new single-user webinar feature that caps out at 1 million attendees. The addition comes less than a month after the #WinWithBlackWomen fundraiser for Vice President…  On Sunday, former President Donald Trump posted a collection of memes on Truth Social — the platform owned by his media company — that make it seem like Taylor Swift…  Few truly autonomous systems are deployed on the battlefield, but one startup is looking to change that with robotic systems that use cooperative behavior to boost troops’ intelligence and tactical…  Former a16z-investor Balaji Srinivasan has booked out an island in Singapore to create his own “Network School.”  The flight tracking company says the misconfiguration exposed customer names, addresses, and pilot’s data, as well as Social Security numbers.  Over 30% of 7- to 9-year-olds have an X account, according to a new report.  Apple Podcasts can now be streamed from the web. Apple announced on Monday that its Apple Podcasts app is now available on all major web browsers (Chrome, Edge, Firefox, and…  Historic vehicles, flowing champagne and fashion have dominated the events at Monterey Car Week for decades now. But a change is afoot: EVs, tech-centric vehicles, startups and a heavy dose…  The clock is ticking! You’ve got just 5 days left to lock in discounted tickets for TechCrunch Disrupt 2024. Save up to $600 on individual ticket types. This limited-time offer ends…  General Motors is cutting around 1,000 software workers around the world in a bid to focus on more “high-priority” initiatives like improving its Super Cruise driver assistance system, the quality…  Popular iPad design app Procreate is coming out against generative AI, and has vowed never to introduce generative AI features into its products. The company said on its website that…  Mike Lynch, the investor and high-profile founder of U.K. tech firm Autonomy, has been declared missing at sea after the yacht he was on, the Bayesian, capsized in a storm…  ElevenLabs, which develops AI-powered tools to create and edit synthetic voices, is making its Reader app available globally with support for 32 languages.  AMD is acquiring ZT Systems, which provides compute design and infrastructure for AI, cloud and general purpose computing, for $4.9 billion.  Amazon is considering shifting its payments offerings in India into a standalone app, three sources familiar with the matter told TechCrunch, as the e-commerce giant aims to boost usage of…  Root helps food and beverage companies collect primary data on their agricultural supply chains.   In May, the African fintech processed up to $70 million in monthly payment volume.  This post contains spoilers for the movie “Alien: Romulus” In the long-running “Alien” movie franchise, the Weyland-Yutani Corporation can’t seem to let go of a terrible idea: It keeps trying…  Thomas Ingenlath is having perhaps a little too much fun in his Polestar 3, silently rocketing away from stop signs and swinging through tightening bends, grinning like a man far…  Some parents have reservations about the South Korean government’s plans to bring tablets with AI-powered textbooks into classrooms, according to a report in Financial Times. The tablets are scheduled to…  Featured Article Season 3 of “Industry” focuses on the fictional bank Pierpoint and blends the worlds — and drama — of tech, media, government and finance.  Featured Article Selling under such circumstances is often not as poor of an outcome for founders and key staff as it initially seems.   While the rapid pace of funding has slowed, many fintechs are continuing to see growth and expand their teams.  This is just one area of leadership where Parker Conrad takes a contrarian approach. He also said he doesn’t believe in top-down management.  Congresswoman Nancy Pelosi issued a statement late yesterday laying out her opposition to SB 1047, a California bill that seeks to regulate AI. “The view of many of us in…  Powered by WordPress VIP