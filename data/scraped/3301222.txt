UK Edition Artificial intelligence programs that mimic speech have been used to impersonate politicians and celebrities, saying implausible or outrageous things yet sounding awfully like them. They can also do an impression of a close relative calling to ask for money, as part of a new type of telephone scam that has proved convincing to some of its targets. Benjamin Parker, 39, from Alberta, Canada, said his parents had received a call from someone who identified themselves as a lawyer. Their son had been involved in a car accident that had killed an American diplomat, and he was in jail, the caller said. Then the caller put their son on the line, saying he loved them and needed them to make a payment of C$21,000 — about £12,800 — before a court hearing the next day. The call may have been suspicious but the voice on the phone sounded just like his, Parker said. The couple made withdrawals from several banks and then made a payment to the supposed lawyer in bitcoin, as requested. That evening they were confused to receive a call from Parker himself, who did not know what they were talking about. He is not sure where they got his voice from, though AI voice generators can produce a close impression of someone based on a few sentences of speech. “Your voicemail on your phone is probably enough,” he said. “My voicemail is 30 to 35 seconds long. That’s more than enough.” The software programs, some freely available online, can then generate the same voice reading a script. Parker said the scammers appeared to target the elderly, having researched the names of immediate relatives and chosen one for impersonation. “I’m usually the one that tells them if something’s a scam or not. Every time my parents said: ‘This sounds suspicious’, I would appear [in the phone call] saying: ‘No, it’s OK, bitcoin transfers are a normal thing,’” he said. © Times Media Limited 2024. Registered in England No. 894646. Registered office: 1 London Bridge Street, SE1 9GF.