In January 2023, when ChatGPT was setting new growth records, Bengaluru-based software engineer Sukuru Sai Vineet launched GitaGPT. The chatbot, powered by GPT-3 technology, provides answers based on the Bhagavad Gita, a 700-verse Hindu scripture. GitaGPT mimics the Hindu god Krishna’s tone — the search box reads, “What troubles you, my child?” In the Bhagavad Gita, according to Vineet, Krishna plays a therapist of sorts for the character Arjuna. A religious AI bot works in a similar manner, Vineet told Rest of World, “except you’re not actually talking to Krishna. You’re talking to a bot that’s pretending to be him.” At least five GitaGPTs have sprung up between January and March this year, with more on the way. Experts have warned that chatbots being allowed to play god might have unintended, and dangerous, consequences. Rest of World found that some of the answers generated by the Gita bots lack filters for casteism, misogyny, and even law. Three of these bots, for instance, say it is acceptable to kill another if it is one’s dharma or duty. “It feels like this is a great thing [to build] for people starting out in tech, who want to get recognition and respect,” Viksit Gaur, a San Francisco-based entrepreneur and former head of user-facing AI at Dropbox, told Rest of World. “But someone else might pick up on this and say, ‘What if I could use this to shape opinion and drive my own agenda?’ And that’s where things get really insidious. So there is a lot of scope for danger here.” Since OpenAI shared its API at the end of November 2022, it has become incredibly easy for software engineers, coders, and anyone with the motivation and know-how to create their own niche versions of an AI chatbot. “Religion is the single largest business in India,” Jaspreet Bindra, AI researcher and author of The Tech Whisperer, a book on AI and other emerging technologies, told Rest of World. “Some of the best scholars of the Upanishads, the Gita, and various other texts that I encounter are hardcore software engineers or IT professionals. So I’m not surprised, and I’m sure there will be many more [chatbots] built on multiple religious texts.” GitaGPTs promise to “unlock life’s mysteries with Krishna,” and act as an “AI-powered spiritual companion.” One even has the audio of a flute, Krishna’s signature instrument, playing in the background. Some of them are answering up to 50,000 questions a day; one chatbot has generated an estimated 10 million answers to date. The tech generates believable answers based on statistical probabilities, Gaur said. “What scares me is that people might interpret this random statistical output as gospel.” Rest of World engaged with the various chatbots on subjects such as gender, caste, religion, and found that not only did some responses seem regressive, most of the takes on dharma were rather concerning. Religious chatbots have the potential to be helpful, by demystifying books like the Bhagavad Gita and making religious texts more accessible, Bindra said. But they could also be used by a few to further their own political or social interests, he noted. And, as with all AI, these chatbots already display certain political biases.  Rest of World found that three of the Gita chatbots held strong opinions on India’s prime minister, Narendra Modi, whose Bharatiya Janata Party has close links to right-wing, Hindu nationalist group Rashtriya Swayamsevak Sangh. While the chatbots praised Modi, they criticized his political opponent, Rahul Gandhi. Anant Sharma’s GitaGPT declared Gandhi “not competent enough to lead the country,” while Vikas Sahu’s Little Krishna chatbot said he “could use some more practice in his political strategies.” For the software engineers who have built the Gita chatbots, though, some of these inconsistencies can be explained away by the technology. “If you gave the Gita to 10 different intellectuals, they can have 10 different ways of [understanding] it,” Sharma told Rest of World, adding that this is the AI’s interpretation of the Gita. A disclaimer on his website requests users to use their discretion, and not “base your decisions on this experimental AI project.” Sahu’s chatbot has had “a few complaints depending on what customers search for,” he told Rest of World. “But then we change the model, we solve it. We are still learning from the model and making it better, making the GPT better.” Rest of World reached out to the creators of all five chatbots, but didn’t get a response from Kishan Kumar or the Ved Vyas Foundation. Sharma got the idea for his GitaGPT after seeing some Twitter buzz on a BibleGPT, created by Andrew Kean Gao, a freshman at Stanford University. Gao’s chatbot offers answers in English or Spanish, with a clear warning at the bottom of the page: “The AI is not 100% accurate. You should exercise your own judgment and take actions according to your own judgment and beliefs. Do not use this site to choose your actions.” In February, chatbots based on the Quran caused a stir online. One of them, Ask Quran, generated responses with advice to “kill the polytheist wherever they are found.” The chatbot has since been paused, following “feedback from the community,” according to the website. The creator for HadithGPT has shut down the chatbot, with a message on the platform saying they decided to “consult with scholars to find a better use for this technology.” “This is the thing with technology. No one knows what it will become when it truly reaches scale,” Vineet said. “So morality is not in the tool, it’s in the guy who’s using the tool. That’s why I’m emphasizing individual responsibility.” “I just build the knives,” he said. “Now if people want to use it to murder or to cut vegetables, that’s not really in my hands, right?”