One of the most prominent pirated book repositories used for training AI, Books3, has been kicked out from the online nest it had been roosting in for nearly three years. Rights-holders have been at war with online pirates for decades, but artificial intelligence is like oil seeping into copyright law‚Äôs water. The two simply do not mix, and the fumes rising from the surface just need a spark to set the entire concept of intellectual property rights alight. As first reported by TorrentFreak, the large pirate repository The Eye took down the Books3 dataset after the Danish anti-piracy group Rights Alliance sent the site a DMCA takedown. Now trying to access that dataset gives a 404 error. The Eye still hosts other training data for AI, but the portion allotted for books has vanished. Rights Alliance told Gizmodo it sent The Eye a takedown request, and the site took down the content last month. The group said the Books3 dataset contained around 150 titles published by their member companies. Rights Alliance also reached out to AI model hosting site Hugging Face (which hosted a datacard and link to the Books3 download) as well as EleutherAI. Both organizations pointed the anti-piracy group toward The Eye. The nonprofit research group EleutherAI originally released Books3 as a part of the AI training set The Pile, an 800 GB open source chunk of training data comprising 22 other datasets specifically designed for training language models. Rights Group said the organization ‚Äúdenied responsibility‚Äù for Books3. Gizmodo reached out to EleutherAI for comment, but we did not receive a response. The Eye claims it regularly complies with all valid DMCA requests, though that data set was originally uploaded by AI developer and prominent open source AI proponent Shawn Presser back in 2020. His stated goal at the time was to open up AI development beyond companies like OpenAI, which trained its earlier large language models on the still-unknown ‚ÄúBooks1‚Äù and ‚ÄúBooks2‚Äù repositories. The Books3 repository contained 196,640 books all in plain.txt format and was supposed to give fledgling AI projects a leg up against the likes of ChatGPT-maker OpenAI. Over Twitter DM, Presser called the attack on Books3 a travesty for open source AI.  While other major companies and VC-funded startups get away with including copyrighted data in their training data, grassroots projects need something to compete‚Äîand that‚Äôs what Books3 was for. ‚ÄúThe only way to replicate models like ChatGPT is to create datasets like Books3,‚Äù Presser said. ‚ÄúAnd every for-profit company does this secretly, without releasing the datasets to the public‚Ä¶ without Books3, we live in a world where nobody except OpenAI and other billion-dollar companies have access to those books‚Äîmeaning you can‚Äôt make your own ChatGPT. No one can. Only billion-dollar companies would have the resources to do that.‚Äù For as long as the media industry groups have fought against piracy, few expected the next front to the neverending copyright war would be AI. In a phone interview with Gizmodo, Rights Alliance CEO Maria Fredenslund said the organization is actively working to take down other copies of Books3. But this is just the start, and anti-piracy groups now have a new target to focus on compared to the usual boogeymen of file-sharing services and pirate libraries. ‚ÄúWe are very worried. It‚Äôs a really huge development in technology and how the content is used,‚Äù Fredenslund said. ‚ÄúIn a way, we see it as the same as 10 years ago when we discussed file sharing, and governments were very afraid of regulating the internet because, in their eyes, everything had to be free. It turned out that copyright also needed to be regulated on the internet as well as in any other aspect.‚Äù It‚Äôs not like there are no more copies of Books3 being hosted on the internet. After the books were taken down last week, Presser posted two new Books3 download links on his Twitter profile. Rights Group said it will continue to pursue sites that host the dataset, but as any old salt of an internet pirate would tell you, once a file‚Äôs out and available, it never truly goes away. Comedian Sarah Silverman was just one of several authors who signed on to a class action lawsuit against Meta, claiming the company stole their books in order to train their LlaMA AI. The lawsuit mentions that Meta used the Books3 repository for training its AI, but added that Meta did not mention what works were contained within those gigabytes of data. In its whitepaper describing the original LlaMA language model, Meta researchers described Books3 as a ‚Äúpublicly available dataset for training large language models.‚Äù Meta referenced this dataset coming from The Pile. Growing AI models requires an enormous amount of information, and for close to a decade the technology‚Äôs development has depended on using protected text. Earlier versions of OpenAI‚Äôs language model from just two or three years ago were trained on datasets like BookCorpus, which contained thousands of scraped-up scraps of book text from sites like Smashwords. That dataset was only a few gigabytes of data, but researchers found that it included works that were copyrighted, or required payment to access. OpenAI‚Äôs GPT-3 model used the Books2 training set to train its AI. Both Books1 and Books2 make up close to 15% of GPT-3‚Äôs training data, though there‚Äôs little to no precise information on what‚Äôs contained in it. Some have speculated the Books2 data was scraped from Libgen, the open source pirate library also called Library Genesis. There‚Äôs even less information on what‚Äôs contained in GPT-4‚Äôs 45 terabytes worth of training data. Big tech companies are increasingly uninterested in sharing this data, knowing the more they do, the more other people can build similar AI models, or tangle them up in lawsuits. Then again, the costs for training these massive models are staggering, especially for larger models. A journalist asked me today why LLMs are currently monopolized by Big Tech companies. With $$$  like this, who else can compete? (And of course Meta didn't actually spend this money, but for those who don't have easy access to a supercomputer, this is what it would cost) https://t.co/t3C25BinQv ‚Äî Sasha Luccioni, PhD ü¶ãüåé‚ú®ü§ó (@SashaMTL) July 27, 2023  But while OpenAI has been revealing less of its training data over the years, we know exactly what‚Äôs gone into the Books3 repository. The dataset was derived from a copy of the Bibliotik library. Bibliotik is a so-called ‚Äúshadow library‚Äù akin to other, industry-derided sources like Libgen, Z-Library, and Sci-Hub. Presser had to build scripts that managed to turn PDFs and images into usable .txt files, a very labor-intensive task. ‚ÄúMy goal was to make it so that anybody could [create these models.] It felt crucial that you and I could create our own ChatGPT if we wanted to,‚Äù Presser said. ‚ÄúUnless authors intend to somehow take ChatGPT offline, or sue them out of existence, then it‚Äôs crucial that you and I can make our own ChatGPTs, for the same reason it was crucial that anybody could make their own website back in the ‚Äò90s.‚Äù Fredenslund said their group was looking to ‚Äúreach out‚Äù to Meta about this copyrighted content being used to train its AI. While the tech giant that is Meta is unlikely to retrain its entire AI model to placate copyright holders, there‚Äôs little worldwide regulation mandating transparency for AI models. While the European Union is currently working on an AI Act that will force companies to have some model transparency, Fredenslund said AI developers need to be forced to share the specifics of their training data, including what precise works were used to create their AI models. ‚ÄúWe hope this attitude toward using illegal content will change, that they will not do that in the future,‚Äù she said. ‚ÄúWe want to be able to actually control the copyright in this aspect, then we actually need to know what the models are trained on.‚Äù As noted in past forum comments, Presser actively worked with EleutherAI to add the Books3 dataset to The Pile. EleutherAI has used The Pile and other data to craft its own AI models, including one called GPT-J that was originally meant to compete with OpenAI‚Äôs GPT-3. Meta went as far as to claim that the original LlaMA-65B model didn‚Äôt perform as well as some other, larger models like the PaLM-540B because it ‚Äúused a limited amount of books and academic papers‚Äù in its pre-training data. The original LlaMA was also formatted on C4, a version of Common Crawl that was a large dataset of mass amounts of internet data. Researchers found that the C4 training set included mass amounts of published work, including propaganda and far-right websites. Those researchers told the Washington Post the copyright symbol appeared more than 200 million times in the C4 training set. Since then, Meta has clammed up hard about what goes into its language models. Last month, Meta released a newer, bigger language model called LlaMA 2. This time, Meta worked with Microsoft to add 40% more data than its previous model, though in its whitepaper the company was much more hesitant to outright state what data its latest LM was trained on. The only reference to its training data was that it‚Äôs ‚Äúa new mix of publicly available online data.‚Äù As the friction between AI and copyright grows hotter, companies are less and less likely to share exactly what‚Äôs contained in the morass of AI training data. 
          An attempt to influence the U.S. presidential election harnessed ChatGPT to generate stories and social media comments, per OpenAI.
         
          The Roto VR Explorer chair swivels a full 360 degrees and has rumble built into the seat. 

         
          Pixel Screenshots app will let you categorize, search through, and add notes to your screenshots. Best of all, it's not auto-screenshotting everything on your phone.

         
          A Microsoft report cited by the campaign details a June phishing attack carried out by "Iranian actors."
         
          The tool can ‚Äòreliably‚Äô detect AI-generated text with watermarks, but OpenAI is still ‚Äòweighing the risks‚Äô of releasing it.
         
          Presented with complex medical scenarios, ChatGPT gave the wrong answer more than half the time and often missed crucial information. 
         We may earn a commission when you buy through links on our sites.
¬©2024 GIZMODO USA LLC. All rights reserved. Mode 
                Follow us
               Mode 
                Follow us
              