Algunos cientÃ­ficos empiezan a preocuparse por los resÃºmenes (o abstract) de investigaciones que pueden generarse por medio del ChatGPT, un chatbot de inteligencia artificial que crea textos a partir de las indicaciones de usuarios y que fue lanzado el pasado 30 de noviembre por la empresa de software OpenAI, con sede en San Francisco. Luego de su lanzamiento, empezaron a surgir dudas entre los cientÃ­ficos sobre los problemas Ã©ticos que podrÃ­an relacionarse con el uso del chatbot y la redacciÃ³n cientÃ­fica. Catherine Gao, de la Universidad de Northwestern en Chicago, junto a un grupo de investigadores, utilizÃ³ ChatGPT para hacer resÃºmenes de estudios y revisar si otros cientÃ­ficos podÃ­an identificar que eran hechos por inteligencia artificial. (Le puede interesar: En video: Telescopio Hubble capta a un agujero negro â€œdevorandoâ€ una estrella) Le pidieron al chatbot que realizara el resumen de 50 investigaciones publicadas en las revistas JAMA , The New England Journal of Medicine , The BMJ , The Lancet y Nature Medicine. Luego compararon estos resÃºmenes con los resÃºmenes originales de las investigaciones a travÃ©s de un detector de plagio y un detector de salida de Inteligencia Artificial. No se detectÃ³ plagio, pero sÃ­ inteligencia artificial en el 66 % de los resÃºmenes del chatbot. Luego, les pidieron a investigadores mÃ©dicos que diferenciaran entre los resÃºmenes hechos por el chatbot y los originales. Identificaron el 68 % de los resÃºmenes generados y el 86 % de los originales, y detectaron incorrectamente el 32 % de los generados como originales y el 14 % de los originales como generados. (Lea: La pifia de unos egresados de Uniandes: explicar la astrologÃ­a con fÃ­sica cuÃ¡ntica) â€œChatGPT escribe resÃºmenes cientÃ­ficos creÃ­blesâ€, seÃ±alÃ³ el equipo de Gao, por lo que sugieren que deben empezarse a evaluar â€œlos lÃ­mites del uso Ã©tico y aceptable de grandes modelos lingÃ¼Ã­sticos para ayudar a la redacciÃ³n cientÃ­ficaâ€. La investigaciÃ³n se encuentra en proceso de prepublicaciÃ³n (preprint). Sandra Wachter, investigadora de la Universidad de Oxford y quien no hizo parte del estudio, seÃ±alÃ³ para la revista Nature que el hecho de que los cientÃ­ficos no puedan determinar cuando un resumen es original podrÃ­a traer â€œconsecuencias nefastasâ€. Para Wachter podrÃ­a haber â€œimplicaciones para la sociedad en general porque la investigaciÃ³n cientÃ­fica juega un papel muy importanteâ€. (Lea: Â¿Y si las mujeres hubieran sido las primeras en llegar al espacio?) Por su parte, Arvind Narayanan, de la Universidad de Princeton en Nueva Jersey, seÃ±alÃ³ para Nature que â€œes poco probable que algÃºn cientÃ­fico serio use ChatGPT para generar resÃºmenes. La pregunta es si la herramienta puede generar un resumen que sea preciso y convincente. No puede, por lo que la ventaja de usar ChatGPT es minÃºscula y la desventaja es significativaâ€. ğŸ‘©â€ğŸ”¬ğŸ“„ Â¿Quieres conocer las Ãºltimas noticias sobre ciencia? Te invitamos a verlas en El Espectador. ğŸ§ªğŸ§¬ Â  Â 