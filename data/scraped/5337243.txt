Algunos científicos empiezan a preocuparse por los resúmenes (o abstract) de investigaciones que pueden generarse por medio del ChatGPT, un chatbot de inteligencia artificial que crea textos a partir de las indicaciones de usuarios y que fue lanzado el pasado 30 de noviembre por la empresa de software OpenAI, con sede en San Francisco. Luego de su lanzamiento, empezaron a surgir dudas entre los científicos sobre los problemas éticos que podrían relacionarse con el uso del chatbot y la redacción científica. Catherine Gao, de la Universidad de Northwestern en Chicago, junto a un grupo de investigadores, utilizó ChatGPT para hacer resúmenes de estudios y revisar si otros científicos podían identificar que eran hechos por inteligencia artificial. (Le puede interesar: En video: Telescopio Hubble capta a un agujero negro “devorando” una estrella) Le pidieron al chatbot que realizara el resumen de 50 investigaciones publicadas en las revistas JAMA , The New England Journal of Medicine , The BMJ , The Lancet y Nature Medicine. Luego compararon estos resúmenes con los resúmenes originales de las investigaciones a través de un detector de plagio y un detector de salida de Inteligencia Artificial. No se detectó plagio, pero sí inteligencia artificial en el 66 % de los resúmenes del chatbot. Luego, les pidieron a investigadores médicos que diferenciaran entre los resúmenes hechos por el chatbot y los originales. Identificaron el 68 % de los resúmenes generados y el 86 % de los originales, y detectaron incorrectamente el 32 % de los generados como originales y el 14 % de los originales como generados. (Lea: La pifia de unos egresados de Uniandes: explicar la astrología con física cuántica) “ChatGPT escribe resúmenes científicos creíbles”, señaló el equipo de Gao, por lo que sugieren que deben empezarse a evaluar “los límites del uso ético y aceptable de grandes modelos lingüísticos para ayudar a la redacción científica”. La investigación se encuentra en proceso de prepublicación (preprint). Sandra Wachter, investigadora de la Universidad de Oxford y quien no hizo parte del estudio, señaló para la revista Nature que el hecho de que los científicos no puedan determinar cuando un resumen es original podría traer “consecuencias nefastas”. Para Wachter podría haber “implicaciones para la sociedad en general porque la investigación científica juega un papel muy importante”. (Lea: ¿Y si las mujeres hubieran sido las primeras en llegar al espacio?) Por su parte, Arvind Narayanan, de la Universidad de Princeton en Nueva Jersey, señaló para Nature que “es poco probable que algún científico serio use ChatGPT para generar resúmenes. La pregunta es si la herramienta puede generar un resumen que sea preciso y convincente. No puede, por lo que la ventaja de usar ChatGPT es minúscula y la desventaja es significativa”. 👩‍🔬📄 ¿Quieres conocer las últimas noticias sobre ciencia? Te invitamos a verlas en El Espectador. 🧪🧬    