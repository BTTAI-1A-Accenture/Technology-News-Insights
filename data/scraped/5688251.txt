Threat of big fines and EU-wide ban hoped to curb manipulative practices and harmful content Unprecedented regulation forcing more than 40 online giants including Facebook, X, Google and TikTok to better police the content they deliver within the EU is due to come into force on 25 August. So what is the legislation and how will regulators enforce it? Digital Services Act (DSA) The DSA is a groundbreaking law that will apply to any digital operation serving the EU, forcing them to be legally accountable for everything from fake news to manipulation of shoppers, Russian propaganda and criminal activity including child abuse. It will apply to large and small operators, but the rules are tiered, with the toughest obligations applying to 17 companies including Facebook and Amazon that have been designated as “very large online platforms”, and two “very large online search engines”: Google and Bing. Those that do not comply face sanctions including large fines – which could run into hundreds of millions of euros – and a EU-wide ban. So what are the new rules? They are themed around five key issues, including online disinformation and other societal risks. 1 Illegal products Platforms will be obliged to combat the sale of illegal products and services, which will affect Amazon and Facebook Marketplace among others. 2 Illegal content New measures are designed to crack down on illegal content – including Russian propaganda, interference with elections, hate crimes and online harms including harassment and child abuse – and ensure that fundamental rights recognised by law across Europe, including freedom of expression and data protection, are safeguarded. 3 Protection of children For parents, unable to police everything their child sees, this cluster of rules is probably the single most important. Platforms will be prohibited from targeting children with advertising based on their personal data or cookies. Big social media firms will be required to redesign their systems to ensure a “high level of privacy, security and safety of minors” and prove they have done so to the European Commission. Platforms will also have to redesign their content “recommender systems” to reduce risks to children. They will also have to carry out a risk assessment of negative effects on children’s mental health and present it to the commission in August. Last year, the world’s largest social media firms were accused of “monetising misery” after an inquest ruled that harmful online content contributed to the death of 14-year-old Molly Russell in the UK. 4 Racial and gender diversity Social media companies will not be able to use sensitive personal data including race, gender and religion to target users with adverts. 5 Ban on “dark patterns” For shoppers, this is protection from everyday interfaces used to manipulate users into buying things they don’t need or want. An audit of 399 online shops by the commission and national consumer authorities this year found that 40% relied on “manipulative practices to exploit consumers’ vulnerabilities or trick them”. The EU justice commissioner revealed that 42 sites used fake countdown timers with fake deadlines for purchasing, with 70 sites “hiding” important information such as delivery costs or the availability of a cheaper option. The audit found that 23 sites hid information with the aim of “manipulating consumers into entering a subscription”. Under the new rules, these should go. Anything else? Consumers will be able to report transgressions and expect changes. Plus, tech companies will be banned from ranking their own services more favourably than others, and they will need to stop making it difficult to uninstall pre-loaded software and apps. What are the big tech companies doing about the new law? “For very large online platforms, the societal stakes are higher, and the rules include additional measures to assess and mitigate societal risks that are linked to their advertising systems, for example in catalysing disinformation,” said a commission spokesperson. The commission’s voluntary code of practice, which is seen as a “nursery slope” to prepare internal systems for the new regulatory regime, has already been endorsed by 44 big tech firms. What about X/Twitter? X, formerly known as Twitter, quit the voluntary code of practice agreement earlier this year, but in June it said it would comply with the rules after a team of EU officials led by the internal market commissioner, Thierry Breton, visited its California HQ to “stress test” the company’s moderation and compliance systems. Breton, the commissioner responsible for enforcing the DSA, welcomed Elon Musk’s change of heart, but warned that there would be “no half measures” when it came to sanctions for online crimes. X/Twitter on notice After his trip to Musk’s HQ in June, Breton said the EU would be extremely vigilant coming up to the EU elections next year. “I told Elon Musk and Linda Yaccarino [Twitter’s chief executive] that Twitter should be very diligent in preparing to tackle illegal content in the European Union. “Fighting disinformation, including pro-Russian propaganda, will also be a focus area in particular as we are entering a period of elections in Europe.” What are the sanctions? A firm that does not comply with the law could face a complete ban in Europe or fines running up to 6% of its global revenue. Last month, X/Twitter said it was on track to generate $3bn (£2.4bn) in revenue. A fine of 6% would be the equivalent of £144m.